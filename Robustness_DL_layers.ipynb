{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of FCN cases in the paper \"are all layers created equal?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn,optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,)), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('./',download = True, train = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = datasets.MNIST('./',download= True, train= False, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64,shuffle = True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization function\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (7): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#define the model \n",
    "inputsize = 784\n",
    "hiddensizes = [256,256,256]\n",
    "outputsize = 10\n",
    "net = nn.Sequential(nn.Linear(inputsize,hiddensizes[0]),nn.ReLU(),nn.Linear(hiddensizes[0],hiddensizes[1]),nn.ReLU(),\n",
    "                    nn.Linear(hiddensizes[1],hiddensizes[2]),nn.ReLU(),nn.Linear(hiddensizes[2],outputsize),nn.LogSoftmax(dim=1))\n",
    "net.apply(init_weights)\n",
    "w_init= list(net.parameters())\n",
    "torch.save(net.state_dict(),'weights_i.pth')\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0],-1)\n",
    "logps = (net(images))\n",
    "loss = criterion(logps,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.41311991288622557\n",
      "\n",
      " Training time in minutes =  0.31357962687810265\n",
      "Epoch 1 - Training loss: 0.1938161818223245\n",
      "\n",
      " Training time in minutes =  0.5853533585866292\n",
      "Epoch 2 - Training loss: 0.1435377686254696\n",
      "\n",
      " Training time in minutes =  0.8783549110094706\n",
      "Epoch 3 - Training loss: 0.11363233616754317\n",
      "\n",
      " Training time in minutes =  1.1872979005177815\n",
      "Epoch 4 - Training loss: 0.09497234638013852\n",
      "\n",
      " Training time in minutes =  1.4982877930005392\n",
      "Epoch 5 - Training loss: 0.0808761963578088\n",
      "\n",
      " Training time in minutes =  1.8090701540311178\n",
      "Epoch 6 - Training loss: 0.06877056525440327\n",
      "\n",
      " Training time in minutes =  2.1140501936276754\n",
      "Epoch 7 - Training loss: 0.06088526386182819\n",
      "\n",
      " Training time in minutes =  2.421694445610046\n",
      "Epoch 8 - Training loss: 0.05279280053975899\n",
      "\n",
      " Training time in minutes =  2.732470198472341\n",
      "Epoch 9 - Training loss: 0.04566774734962128\n",
      "\n",
      " Training time in minutes =  3.0414255460103354\n",
      "Epoch 10 - Training loss: 0.04079383348739311\n",
      "\n",
      " Training time in minutes =  3.3487879236539206\n",
      "Epoch 11 - Training loss: 0.03605475245730709\n",
      "\n",
      " Training time in minutes =  3.658428680896759\n",
      "Epoch 12 - Training loss: 0.031230753536017408\n",
      "\n",
      " Training time in minutes =  3.9647446354230245\n",
      "Epoch 13 - Training loss: 0.026707375736118776\n",
      "\n",
      " Training time in minutes =  4.27214648326238\n",
      "Epoch 14 - Training loss: 0.025000056584188437\n",
      "\n",
      " Training time in minutes =  4.581049370765686\n",
      "Epoch 15 - Training loss: 0.021105325051289456\n",
      "\n",
      " Training time in minutes =  4.893666982650757\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(net.parameters(),lr = 0.003, momentum = 0.9 )\n",
    "time0 = time()\n",
    "epochs =16\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images,labels in trainloader:\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "#     else:\n",
    "    print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
    "#     print(running_loss)\n",
    "            \n",
    "    print(\"\\n Training time in minutes = \", (time()-time0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'weights_f.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.9772\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        with torch.no_grad():\n",
    "            logps = net(img)\n",
    "\n",
    "    \n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "              correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wi = torch.load('weights_i.pth')\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf['0.bias'] = wi['0.bias']\n",
    "wf['0.weight'] = wi['0.weight']\n",
    "torch.save(wf,'weights_exp1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint= 0 \n",
      "Model Accuracy = 0.5299\n",
      "checkpoint= 2 \n",
      "Model Accuracy = 0.9708\n",
      "checkpoint= 4 \n",
      "Model Accuracy = 0.97\n",
      "checkpoint= 8 \n",
      "Model Accuracy = 0.9772\n"
     ]
    }
   ],
   "source": [
    "#testing with layer 1 re-initialized \n",
    "#testing\n",
    "cpt = [0,2,4,8,16]\n",
    "ctr = 0\n",
    "\n",
    "for i in range(16):\n",
    "    \n",
    "    for j in cpt:\n",
    "        if (j == ctr):\n",
    "            #run testing\n",
    "            net.load_state_dict(torch.load('weights_exp1.pth'))\n",
    "            correct_count, all_count = 0, 0\n",
    "            for images,labels in valloader:\n",
    "                for i in range(len(labels)):\n",
    "                    img = images[i].view(1, 784)\n",
    "                    with torch.no_grad():\n",
    "                        logps = net(img)\n",
    "                    ps = torch.exp(logps)\n",
    "                    probab = list(ps.numpy()[0])\n",
    "                    pred_label = probab.index(max(probab))\n",
    "                    true_label = labels.numpy()[i]\n",
    "                    if(true_label == pred_label):\n",
    "                          correct_count += 1\n",
    "                    all_count += 1\n",
    "            print(\"checkpoint=\",ctr,\"\\nModel Accuracy =\", (correct_count/all_count))\n",
    "\n",
    "    \n",
    "    #run training\n",
    "    running_loss = 0\n",
    "    for images,labels in trainloader:\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        torch.save(net.state_dict(),'weights_exp1.pth')    \n",
    "                \n",
    "    ctr = ctr + 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint= 0 \n",
      "Model Accuracy = 0.9463\n",
      "checkpoint= 2 \n",
      "Model Accuracy = 0.9775\n",
      "checkpoint= 4 \n",
      "Model Accuracy = 0.9723\n",
      "checkpoint= 8 \n",
      "Model Accuracy = 0.9791\n"
     ]
    }
   ],
   "source": [
    "#changing layer 2 weights\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf['2.bias'] = wi['2.bias']\n",
    "wf['2.weight'] = wi['2.weight']\n",
    "torch.save(wf,'weights_exp2.pth')\n",
    "#testing with layer 1 re-initialized \n",
    "#testing\n",
    "cpt = [0,2,4,8,16]\n",
    "ctr = 0\n",
    "\n",
    "for i in range(16):\n",
    "    \n",
    "    for j in cpt:\n",
    "        if (j == ctr):\n",
    "            #run testing\n",
    "            net.load_state_dict(torch.load('weights_exp2.pth'))\n",
    "            correct_count, all_count = 0, 0\n",
    "            for images,labels in valloader:\n",
    "                for i in range(len(labels)):\n",
    "                    img = images[i].view(1, 784)\n",
    "                    with torch.no_grad():\n",
    "                        logps = net(img)\n",
    "                    ps = torch.exp(logps)\n",
    "                    probab = list(ps.numpy()[0])\n",
    "                    pred_label = probab.index(max(probab))\n",
    "                    true_label = labels.numpy()[i]\n",
    "                    if(true_label == pred_label):\n",
    "                          correct_count += 1\n",
    "                    all_count += 1\n",
    "            print(\"checkpoint=\",ctr,\"\\nModel Accuracy =\", (correct_count/all_count))\n",
    "\n",
    "    \n",
    "    #run training\n",
    "    running_loss = 0\n",
    "    for images,labels in trainloader:\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        torch.save(net.state_dict(),'weights_exp2.pth')    \n",
    "                \n",
    "    ctr = ctr + 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint= 0 \n",
      "Model Accuracy = 0.9528\n",
      "checkpoint= 2 \n",
      "Model Accuracy = 0.979\n",
      "checkpoint= 4 \n",
      "Model Accuracy = 0.9787\n",
      "checkpoint= 8 \n",
      "Model Accuracy = 0.9786\n"
     ]
    }
   ],
   "source": [
    "#changing layer 3 weights\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf['4.bias'] = wi['4.bias']\n",
    "wf['4.weight'] = wi['4.weight']\n",
    "torch.save(wf,'weights_exp3.pth')\n",
    "#testing with layer 3 re-initialized \n",
    "cpt = [0,2,4,8,16]\n",
    "ctr = 0\n",
    "\n",
    "for i in range(16):\n",
    "    \n",
    "    for j in cpt:\n",
    "        if (j == ctr):\n",
    "            #run testing\n",
    "            net.load_state_dict(torch.load('weights_exp3.pth'))\n",
    "            correct_count, all_count = 0, 0\n",
    "            for images,labels in valloader:\n",
    "                for i in range(len(labels)):\n",
    "                    img = images[i].view(1, 784)\n",
    "                    with torch.no_grad():\n",
    "                        logps = net(img)\n",
    "                    ps = torch.exp(logps)\n",
    "                    probab = list(ps.numpy()[0])\n",
    "                    pred_label = probab.index(max(probab))\n",
    "                    true_label = labels.numpy()[i]\n",
    "                    if(true_label == pred_label):\n",
    "                          correct_count += 1\n",
    "                    all_count += 1\n",
    "            print(\"checkpoint=\",ctr,\"\\nModel Accuracy =\", (correct_count/all_count))\n",
    "\n",
    "    \n",
    "    #run training\n",
    "    running_loss = 0\n",
    "    for images,labels in trainloader:\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        torch.save(net.state_dict(),'weights_exp3.pth')    \n",
    "                \n",
    "    ctr = ctr + 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint= 0 \n",
      "Model Accuracy = 0.9493\n",
      "checkpoint= 2 \n",
      "Model Accuracy = 0.9785\n",
      "checkpoint= 4 \n",
      "Model Accuracy = 0.9792\n",
      "checkpoint= 8 \n",
      "Model Accuracy = 0.9779\n"
     ]
    }
   ],
   "source": [
    "#changing layer 4 weights\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf['6.bias'] = wi['6.bias']\n",
    "wf['6.weight'] = wi['6.weight']\n",
    "torch.save(wf,'weights_exp4.pth')\n",
    "#testing with layer 4 re-initialized \n",
    "cpt = [0,2,4,8,16]\n",
    "ctr = 0\n",
    "\n",
    "for i in range(16):\n",
    "    \n",
    "    for j in cpt:\n",
    "        if (j == ctr):\n",
    "            #run testing\n",
    "            net.load_state_dict(torch.load('weights_exp4.pth'))\n",
    "            correct_count, all_count = 0, 0\n",
    "            for images,labels in valloader:\n",
    "                for i in range(len(labels)):\n",
    "                    img = images[i].view(1, 784)\n",
    "                    with torch.no_grad():\n",
    "                        logps = net(img)\n",
    "                    ps = torch.exp(logps)\n",
    "                    probab = list(ps.numpy()[0])\n",
    "                    pred_label = probab.index(max(probab))\n",
    "                    true_label = labels.numpy()[i]\n",
    "                    if(true_label == pred_label):\n",
    "                          correct_count += 1\n",
    "                    all_count += 1\n",
    "            print(\"checkpoint=\",ctr,\"\\nModel Accuracy =\", (correct_count/all_count))\n",
    "\n",
    "    \n",
    "    #run training\n",
    "    running_loss = 0\n",
    "    for images,labels in trainloader:\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        torch.save(net.state_dict(),'weights_exp4.pth')    \n",
    "                \n",
    "    ctr = ctr + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.0758\n"
     ]
    }
   ],
   "source": [
    "#checking for re-randomization performance\n",
    "#re-randomizing layer 1 weights\n",
    "wf= torch.load('weights_f.pth')\n",
    "torch.nn.init.xavier_uniform_(wf['0.weight'])\n",
    "wf['0.bias'].data.fill_(0.01)\n",
    "\n",
    "torch.save(wf,'weights_exp_rerand_1.pth')\n",
    "#testing with layer 1 re-initialized \n",
    "#testing\n",
    "net.load_state_dict(torch.load('weights_exp_rerand_1.pth'))\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        with torch.no_grad():\n",
    "            logps = net(img)\n",
    "\n",
    "    \n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "              correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.1045\n"
     ]
    }
   ],
   "source": [
    "#checking for re-randomization performance\n",
    "#re-randomizing layer 2 weights\n",
    "wf= torch.load('weights_f.pth')\n",
    "torch.nn.init.xavier_uniform_(wf['2.weight'])\n",
    "wf['2.bias'].data.fill_(0.01)\n",
    "\n",
    "torch.save(wf,'weights_exp_rerand_2.pth')\n",
    "#testing with layer 1 re-initialized \n",
    "#testing\n",
    "net.load_state_dict(torch.load('weights_exp_rerand_2.pth'))\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        with torch.no_grad():\n",
    "            logps = net(img)\n",
    "\n",
    "    \n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "              correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.2064\n"
     ]
    }
   ],
   "source": [
    "#checking for re-randomization performance\n",
    "#re-randomizing layer 3 weights\n",
    "wf= torch.load('weights_f.pth')\n",
    "torch.nn.init.xavier_uniform_(wf['4.weight'])\n",
    "wf['4.bias'].data.fill_(0.01)\n",
    "\n",
    "torch.save(wf,'weights_exp_rerand_3.pth')\n",
    "#testing with layer 1 re-initialized \n",
    "#testing\n",
    "net.load_state_dict(torch.load('weights_exp_rerand_3.pth'))\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        with torch.no_grad():\n",
    "            logps = net(img)\n",
    "\n",
    "    \n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "              correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.2064\n"
     ]
    }
   ],
   "source": [
    "#checking for re-randomization performance\n",
    "#re-randomizing layer 4 weights\n",
    "wf= torch.load('weights_f.pth')\n",
    "torch.nn.init.xavier_uniform_(wf['6.weight'])\n",
    "wf['6.bias'].data.fill_(0.01)\n",
    "\n",
    "torch.save(wf,'weights_exp_rerand_4.pth')\n",
    "#testing with layer 1 re-initialized \n",
    "#testing\n",
    "net.load_state_dict(torch.load('weights_exp_rerand_3.pth'))\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        with torch.no_grad():\n",
    "            logps = net(img)\n",
    "\n",
    "    \n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "              correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wi = torch.load('weights_i.pth')\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf['0.bias'] = wi['0.bias']\n",
    "wf['0.weight'] = wi['0.weight']\n",
    "torch.save(wf,'weights_exp1.pth')\n",
    "\n",
    "wi = torch.load('weights_i.pth')\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf['2.bias'] = wi['2.bias']\n",
    "wf['2.weight'] = wi['2.weight']\n",
    "torch.save(wf,'weights_exp2.pth')\n",
    "\n",
    "wi = torch.load('weights_i.pth')\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf['4.bias'] = wi['4.bias']\n",
    "wf['4.weight'] = wi['4.weight']\n",
    "torch.save(wf,'weights_exp3.pth')\n",
    "\n",
    "wi = torch.load('weights_i.pth')\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf['6.bias'] = wi['6.bias']\n",
    "wf['6.weight'] = wi['6.weight']\n",
    "torch.save(wf,'weights_exp4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinit distance L1 6.6157546043396\n",
      "Reinit distance L2 4.034752368927002\n",
      "Reinit distance L3 3.7830379009246826\n",
      "Reinit distance L4 3.2720789909362793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\anaconda3\\lib\\site-packages\\torch\\tensor.py:362: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    }
   ],
   "source": [
    "#L2 norm between learned and re initialized weights of l1\n",
    "w_reinit_1= torch.load('weights_exp1.pth')\n",
    "w_reinit_l1 = w_reinit_1['0.weight'].resize(1,784*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf_0=wf['0.weight'].resize(1,784*256)\n",
    "pdist = torch.nn.PairwiseDistance(p=2)\n",
    "\n",
    "print('Reinit distance L1',pdist(wf_0,w_reinit_l1).item())\n",
    "\n",
    "#L norm between learned and re initialized weights of l2\n",
    "w_reinit_2= torch.load('weights_exp2.pth')\n",
    "w_reinit_l2 = w_reinit_2['2.weight'].resize(1,256*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf_2=wf['2.weight'].resize(1,256*256)\n",
    "\n",
    "print('Reinit distance L2',pdist(wf_2,w_reinit_l2).item())\n",
    "\n",
    "#L2 norm between learned and re initialized weights of l3\n",
    "w_reinit_3= torch.load('weights_exp3.pth')\n",
    "w_reinit_l3 = w_reinit_3['4.weight'].resize(1,256*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf_3=wf['4.weight'].resize(1,256*256)\n",
    "\n",
    "print('Reinit distance L3',pdist(wf_3,w_reinit_l3).item())\n",
    "\n",
    "#L2 norm between learned and re initialized weights of l4\n",
    "w_reinit_4= torch.load('weights_exp4.pth')\n",
    "w_reinit_l4 = w_reinit_4['6.weight'].resize(1,256*10)\n",
    "wf= torch.load('weights_f.pth')\n",
    "\n",
    "wf_4=wf['6.weight'].resize(1,256*10)\n",
    "\n",
    "print('Reinit distance L4',pdist(wf_4,w_reinit_l4).item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike as shown in the paper the layer 1 which affects final accuracy the most also accounts for the largest L2 norm difference in initial and final weights is largest as expected from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.204221725463867"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the same for re-randomized weights of layer 1\n",
    "w_rerand_1= torch.load('weights_exp_rerand_1.pth')\n",
    "w_rerand_l1 = w_rerand_1['0.weight'].resize(1,784*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "\n",
    "wf_0=wf['0.weight'].resize(1,784*256)\n",
    "pdist = torch.nn.PairwiseDistance(p=2)\n",
    "\n",
    "pdist(wf_0,w_rerand_l1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.968156814575195"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the same for re-randomized weights of layer 2\n",
    "w_rerand_2= torch.load('weights_exp_rerand_2.pth')\n",
    "w_rerand_l2 = w_rerand_2['2.weight'].resize(1,256*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "\n",
    "wf_2=wf['2.weight'].resize(1,256*256)\n",
    "pdist = torch.nn.PairwiseDistance(p=2)\n",
    "\n",
    "pdist(wf_2,w_rerand_l2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.963138580322266"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the same for re-randomized weights of layer 3\n",
    "w_rerand_3= torch.load('weights_exp_rerand_3.pth')\n",
    "w_rerand_l3 = w_rerand_3['4.weight'].resize(1,256*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "\n",
    "wf_3=wf['4.weight'].resize(1,256*256)\n",
    "pdist = torch.nn.PairwiseDistance(p=2)\n",
    "\n",
    "pdist(wf_3,w_rerand_l3).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.329382419586182"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the same for re-randomized weights of layer 4\n",
    "w_rerand_4= torch.load('weights_exp_rerand_4.pth')\n",
    "w_rerand_l4 = w_rerand_4['6.weight'].resize(1,10*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "\n",
    "wf_4=wf['6.weight'].resize(1,10*256)\n",
    "pdist = torch.nn.PairwiseDistance(p=2)\n",
    "\n",
    "pdist(wf_4,w_rerand_l4).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Here as well, the one change from the trend explained in the paper is that layer 1 has the highest change \n",
    "    in weight in the rerandomized case. Layer 2 and 3 having a larger distance than layer 4 holds true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinity norm distance for l1 0.15976768732070923\n",
      "Infinity norm distance for l2 0.12841816246509552\n",
      "Infinity norm distance for l3 0.11122281104326248\n",
      "Infinity nirm distance l4 0.26753726601600647\n"
     ]
    }
   ],
   "source": [
    "#infinity norm distance layer 1 reinitialization\n",
    "w_reinit_1= torch.load('weights_exp1.pth')\n",
    "w_reinit_l1 = w_reinit_1['0.weight'].resize(1,784*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf_0=wf['0.weight'].resize(1,784*256)\n",
    "\n",
    "print('Infinity norm distance for l1',torch.max(torch.abs((w_reinit_l1 - wf_0))).item())\n",
    "\n",
    "#Linf norm between learned and re initialized weights of l2\n",
    "w_reinit_2= torch.load('weights_exp2.pth')\n",
    "w_reinit_l2 = w_reinit_2['2.weight'].resize(1,256*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf_2=wf['2.weight'].resize(1,256*256)\n",
    "print('Infinity norm distance for l2',torch.max(torch.abs((w_reinit_l2 - wf_2))).item())\n",
    "\n",
    "# l3\n",
    "w_reinit_3= torch.load('weights_exp3.pth')\n",
    "w_reinit_l3 = w_reinit_3['4.weight'].resize(1,256*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf_3=wf['4.weight'].resize(1,256*256)\n",
    "print('Infinity norm distance for l3',torch.max(torch.abs((w_reinit_l3 - wf_3))).item())\n",
    "\n",
    "\n",
    "#Linf norm between learned and re initialized weights of l4\n",
    "w_reinit_4= torch.load('weights_exp4.pth')\n",
    "w_reinit_l4 = w_reinit_4['6.weight'].resize(1,256*10)\n",
    "wf= torch.load('weights_f.pth')\n",
    "wf_4=wf['6.weight'].resize(1,256*10)\n",
    "print('Infinity nirm distance l4',torch.max(torch.abs((w_reinit_l4 - wf_4))).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 4 has the largest Linf norm as shown in the paper. Layer 1 has a smaller Linf norm than layer 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linf norm layer 1: 0.2124536633491516\n",
      "Linf norm layer 2: 0.26174092292785645\n",
      "Linf norm layer 3: 0.2511447072029114\n",
      "Linf norm layer 4: 0.42163801193237305\n"
     ]
    }
   ],
   "source": [
    "#Linf norm between learned and re randomized weights \n",
    "#re-randomized weights of layer 1\n",
    "w_rerand_1= torch.load('weights_exp_rerand_1.pth')\n",
    "w_rerand_l1 = w_rerand_1['0.weight'].resize(1,784*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "\n",
    "wf_0=wf['0.weight'].resize(1,784*256)\n",
    "print('Linf norm layer 1:',torch.max(torch.abs((w_rerand_l1 - wf_0))).item()\n",
    ")\n",
    "\n",
    "# re-randomized weights of layer 2\n",
    "w_rerand_2= torch.load('weights_exp_rerand_2.pth')\n",
    "w_rerand_l2 = w_rerand_2['2.weight'].resize(1,256*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "\n",
    "wf_2=wf['2.weight'].resize(1,256*256)\n",
    "print('Linf norm layer 2:',torch.max(torch.abs((w_rerand_l2 - wf_2))).item()\n",
    ")\n",
    "\n",
    "#re-randomized weights of layer 3\n",
    "w_rerand_3= torch.load('weights_exp_rerand_3.pth')\n",
    "w_rerand_l3 = w_rerand_3['4.weight'].resize(1,256*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "\n",
    "wf_3=wf['4.weight'].resize(1,256*256)\n",
    "print('Linf norm layer 3:',torch.max(torch.abs((w_rerand_l3 - wf_3))).item()\n",
    ")\n",
    "\n",
    "#checking the same for re-randomized weights of layer 4\n",
    "w_rerand_4= torch.load('weights_exp_rerand_4.pth')\n",
    "w_rerand_l4 = w_rerand_4['6.weight'].resize(1,10*256)\n",
    "wf= torch.load('weights_f.pth')\n",
    "\n",
    "wf_4=wf['6.weight'].resize(1,10*256)\n",
    "print('Linf norm layer 4:',torch.max(torch.abs((w_rerand_l4 - wf_4))).item()\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike as shown in the paper (which is layer 2,3, and 4 have similar linf norm and l1 has a low norm), we see Layer 4 has a considerably larger Linf norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use np for norm rechecking \n",
    "Train for 50 epochs on google collab\n",
    "Affine spaces of parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer  1 28.278309\n",
      "layer  2 22.891495\n",
      "layer  3 22.930168\n",
      "layer  4 7.3277464\n"
     ]
    }
   ],
   "source": [
    "#L2 norm trend across layers\n",
    "from numpy import linalg as LA\n",
    "w_reinit_1= torch.load('weights_exp1.pth')\n",
    "w_reinit_2= torch.load('weights_exp2.pth')\n",
    "w_reinit_3= torch.load('weights_exp3.pth')\n",
    "w_reinit_4= torch.load('weights_exp4.pth')\n",
    "\n",
    "w_reinit_l1 = w_reinit_1['0.weight'].resize(1,784*256).numpy()\n",
    "w_reinit_l2 = w_reinit_2['2.weight'].resize(1,256*256).numpy()\n",
    "w_reinit_l3 = w_reinit_3['4.weight'].resize(1,256*256).numpy()\n",
    "w_reinit_l4 = w_reinit_4['6.weight'].resize(1,10*256).numpy()\n",
    "\n",
    "wf= torch.load('weights_f.pth')\n",
    "\n",
    "wf_0=wf['0.weight'].resize(1,784*256).numpy()\n",
    "wf_2=wf['2.weight'].resize(1,256*256).numpy()\n",
    "wf_3=wf['4.weight'].resize(1,256*256).numpy()\n",
    "wf_4=wf['6.weight'].resize(1,10*256).numpy()\n",
    "print('layer  1',LA.norm(w_reinit_l1-wf_0))\n",
    "print('layer  2',LA.norm(w_reinit_l2-wf_2))\n",
    "print('layer  3',LA.norm(w_reinit_l3-wf_3))\n",
    "print('layer  4',LA.norm(w_reinit_l4-wf_4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer  1: linalg.norm value 10331.423 ; max(abs()) value 0.22720364\n",
      "layer  2 linalg.norm value 4785.814 ; max(abs()) value 0.24625365\n",
      "layer  3 linalg.norm value 4787.505 ; max(abs()) value 0.24873625\n",
      "layer  4 linalg.norm value 302.1077 ; max(abs()) value 0.4389783\n"
     ]
    }
   ],
   "source": [
    "#Linf norm trend across layers\n",
    "from numpy import linalg as LA\n",
    "w_reinit_1= torch.load('weights_exp1.pth')\n",
    "w_reinit_2= torch.load('weights_exp2.pth')\n",
    "w_reinit_3= torch.load('weights_exp3.pth')\n",
    "w_reinit_4= torch.load('weights_exp4.pth')\n",
    "\n",
    "w_reinit_l1 = w_reinit_1['0.weight'].resize(1,784*256).numpy()\n",
    "w_reinit_l2 = w_reinit_2['2.weight'].resize(1,256*256).numpy()\n",
    "w_reinit_l3 = w_reinit_3['4.weight'].resize(1,256*256).numpy()\n",
    "w_reinit_l4 = w_reinit_4['6.weight'].resize(1,10*256).numpy()\n",
    "\n",
    "wf= torch.load('weights_f.pth')\n",
    "\n",
    "wf_0=wf['0.weight'].resize(1,784*256).numpy()\n",
    "wf_2=wf['2.weight'].resize(1,256*256).numpy()\n",
    "wf_3=wf['4.weight'].resize(1,256*256).numpy()\n",
    "wf_4=wf['6.weight'].resize(1,10*256).numpy()\n",
    "print('layer  1: linalg.norm value',LA.norm((w_reinit_l1-wf_0),np.inf), '; max(abs()) value',np.max(np.abs(w_reinit_l1-wf_0)))\n",
    "print('layer  2 linalg.norm value',LA.norm(w_reinit_l2-wf_2,np.inf),'; max(abs()) value',np.max(np.abs(w_reinit_l2-wf_2)))\n",
    "print('layer  3 linalg.norm value',LA.norm(w_reinit_l3-wf_3,np.inf),'; max(abs()) value',np.max(np.abs(w_reinit_l3-wf_3)))\n",
    "print('layer  4 linalg.norm value',LA.norm(w_reinit_l4-wf_4,np.inf),'; max(abs()) value',np.max(np.abs(w_reinit_l4-wf_4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (9): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#same robustness experiment with five layers\n",
    "#define the model \n",
    "inputsize = 784\n",
    "hiddensizes = [256,256,256,256]\n",
    "outputsize = 10\n",
    "net5 = nn.Sequential(nn.Linear(inputsize,hiddensizes[0]),nn.ReLU(),nn.Linear(hiddensizes[0],hiddensizes[1]),nn.ReLU(),\n",
    "                    nn.Linear(hiddensizes[1],hiddensizes[2]),nn.ReLU(),nn.Linear(hiddensizes[2],hiddensizes[3]),nn.ReLU(),nn.Linear(hiddensizes[3],outputsize),nn.LogSoftmax(dim=1))\n",
    "net5.apply(init_weights)\n",
    "w_init= list(net5.parameters())\n",
    "torch.save(net5.state_dict(),'weights5_i.pth')\n",
    "print(net5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0],-1)\n",
    "logps = (net5(images))\n",
    "loss = criterion(logps,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.4248684939068518\n",
      "\n",
      " Training time in minutes =  0.20493873755137126\n",
      "Epoch 1 - Training loss: 0.18384488870395715\n",
      "\n",
      " Training time in minutes =  0.4071003278096517\n",
      "Epoch 2 - Training loss: 0.13241435576683042\n",
      "\n",
      " Training time in minutes =  0.6055184006690979\n",
      "Epoch 3 - Training loss: 0.10105363108805501\n",
      "\n",
      " Training time in minutes =  0.8018073519070943\n",
      "Epoch 4 - Training loss: 0.08550828020634459\n",
      "\n",
      " Training time in minutes =  0.9952053149541219\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(net5.parameters(),lr = 0.003, momentum = 0.9 )\n",
    "time0 = time()\n",
    "epochs =5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images,labels in trainloader:\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        optimizer.zero_grad()\n",
    "        output = net5(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "#     else:\n",
    "    print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
    "#     print(running_loss)\n",
    "            \n",
    "    print(\"\\n Training time in minutes = \", (time()-time0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net5.state_dict(),'weights_f5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Layer 1 reinit Model Accuracy = 0.5523\n",
      "\n",
      "Layer 2 reinit Model Accuracy = 0.9483\n",
      "\n",
      "Layer 3 reinit Model Accuracy = 0.9542\n",
      "\n",
      "Layer 4 reinit Model Accuracy = 0.9541\n",
      "\n",
      "Layer 5 reinit Model Accuracy = 0.9541\n"
     ]
    }
   ],
   "source": [
    "#Testing reinitialization performance by changing different layers\n",
    "wi=torch.load('weights5_i.pth')\n",
    "wf= torch.load('weights_f5.pth')\n",
    "wf['0.bias'] = wi['0.bias']\n",
    "wf['0.weight'] = wi['0.weight']\n",
    "torch.save(wf,'weights5_exp1.pth')\n",
    "#testing\n",
    "net5.load_state_dict(torch.load('weights5_exp1.pth'))\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        with torch.no_grad():\n",
    "            logps = net5(img)\n",
    "\n",
    "    \n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "              correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nLayer 1 reinit Model Accuracy =\", (correct_count/all_count))\n",
    "\n",
    "wi=torch.load('weights5_i.pth')\n",
    "wf= torch.load('weights_f5.pth')\n",
    "wf['2.bias'] = wi['2.bias']\n",
    "wf['2.weight'] = wi['2.weight']\n",
    "torch.save(wf,'weights5_exp2.pth')\n",
    "#testing\n",
    "net5.load_state_dict(torch.load('weights5_exp2.pth'))\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        with torch.no_grad():\n",
    "            logps = net5(img)\n",
    "\n",
    "    \n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "              correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "#print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nLayer 2 reinit Model Accuracy =\", (correct_count/all_count))\n",
    "\n",
    "\n",
    "wi=torch.load('weights5_i.pth')\n",
    "wf= torch.load('weights_f5.pth')\n",
    "wf['4.bias'] = wi['4.bias']\n",
    "wf['4.weight'] = wi['4.weight']\n",
    "torch.save(wf,'weights5_exp3.pth')\n",
    "#testing\n",
    "net5.load_state_dict(torch.load('weights5_exp3.pth'))\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        with torch.no_grad():\n",
    "            logps = net5(img)\n",
    "\n",
    "    \n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "              correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "#print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nLayer 3 reinit Model Accuracy =\", (correct_count/all_count))\n",
    "\n",
    "wi=torch.load('weights5_i.pth')\n",
    "wf= torch.load('weights_f5.pth')\n",
    "wf['6.bias'] = wi['6.bias']\n",
    "wf['6.weight'] = wi['6.weight']\n",
    "torch.save(wf,'weights5_exp4.pth')\n",
    "#testing\n",
    "net5.load_state_dict(torch.load('weights5_exp4.pth'))\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        with torch.no_grad():\n",
    "            logps = net5(img)\n",
    "\n",
    "    \n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "              correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "# print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nLayer 4 reinit Model Accuracy =\", (correct_count/all_count))\n",
    "\n",
    "wi=torch.load('weights5_i.pth')\n",
    "wf= torch.load('weights_f5.pth')\n",
    "wf['8.bias'] = wi['8.bias']\n",
    "wf['8.weight'] = wi['8.weight']\n",
    "torch.save(wf,'weights5_exp5.pth')\n",
    "#testing\n",
    "net5.load_state_dict(torch.load('weights5_exp4.pth'))\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)\n",
    "        with torch.no_grad():\n",
    "            logps = net5(img)\n",
    "\n",
    "    \n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.numpy()[i]\n",
    "        if(true_label == pred_label):\n",
    "              correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "# print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nLayer 5 reinit Model Accuracy =\", (correct_count/all_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer  1 4.4859114\n",
      "layer  2 2.5516217\n",
      "layer  3 2.2833698\n",
      "layer  4 2.2638535\n",
      "layer  5 1.962611\n"
     ]
    }
   ],
   "source": [
    "#L2 norm trend across layers\n",
    "from numpy import linalg as LA\n",
    "w_reinit_1= torch.load('weights5_exp1.pth')\n",
    "w_reinit_2= torch.load('weights5_exp2.pth')\n",
    "w_reinit_3= torch.load('weights5_exp3.pth')\n",
    "w_reinit_4= torch.load('weights5_exp4.pth')\n",
    "w_reinit_5= torch.load('weights5_exp5.pth')\n",
    "\n",
    "w_reinit_l1 = w_reinit_1['0.weight'].resize(1,784*256).numpy()\n",
    "w_reinit_l2 = w_reinit_2['2.weight'].resize(1,256*256).numpy()\n",
    "w_reinit_l3 = w_reinit_3['4.weight'].resize(1,256*256).numpy()\n",
    "w_reinit_l4 = w_reinit_4['6.weight'].resize(1,256*256).numpy()\n",
    "w_reinit_l5 = w_reinit_5['8.weight'].resize(1,10*256).numpy()\n",
    "\n",
    "\n",
    "wf= torch.load('weights_f5.pth')\n",
    "\n",
    "wf_0=wf['0.weight'].resize(1,784*256).numpy()\n",
    "wf_2=wf['2.weight'].resize(1,256*256).numpy()\n",
    "wf_3=wf['4.weight'].resize(1,256*256).numpy()\n",
    "wf_4=wf['6.weight'].resize(1,256*256).numpy()\n",
    "wf_5=wf['8.weight'].resize(1,10*256).numpy()\n",
    "\n",
    "\n",
    "print('layer  1',LA.norm(w_reinit_l1-wf_0))\n",
    "print('layer  2',LA.norm(w_reinit_l2-wf_2))\n",
    "print('layer  3',LA.norm(w_reinit_l3-wf_3))\n",
    "print('layer  4',LA.norm(w_reinit_l4-wf_4))\n",
    "print('layer  5',LA.norm(w_reinit_l5-wf_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer  1: linalg.norm value 1153.2687 ; max(abs()) value 0.14283744\n",
      "layer  2 linalg.norm value 407.02307 ; max(abs()) value 0.08732679\n",
      "layer  3 linalg.norm value 374.83377 ; max(abs()) value 0.08170561\n",
      "layer  4 linalg.norm value 361.94498 ; max(abs()) value 0.08172127\n",
      "layer  5 linalg.norm value 67.206696 ; max(abs()) value 0.17559001\n"
     ]
    }
   ],
   "source": [
    "#Linf norm trend across layers\n",
    "from numpy import linalg as LA\n",
    "w_reinit_1= torch.load('weights5_exp1.pth')\n",
    "w_reinit_2= torch.load('weights5_exp2.pth')\n",
    "w_reinit_3= torch.load('weights5_exp3.pth')\n",
    "w_reinit_4= torch.load('weights5_exp4.pth')\n",
    "w_reinit_5= torch.load('weights5_exp5.pth')\n",
    "\n",
    "w_reinit_l1 = w_reinit_1['0.weight'].resize(1,784*256).numpy()\n",
    "w_reinit_l2 = w_reinit_2['2.weight'].resize(1,256*256).numpy()\n",
    "w_reinit_l3 = w_reinit_3['4.weight'].resize(1,256*256).numpy()\n",
    "w_reinit_l4 = w_reinit_4['6.weight'].resize(1,256*256).numpy()\n",
    "w_reinit_l5 = w_reinit_5['8.weight'].resize(1,10*256).numpy()\n",
    "\n",
    "wf= torch.load('weights_f5.pth')\n",
    "\n",
    "wf_0=wf['0.weight'].resize(1,784*256).numpy()\n",
    "wf_2=wf['2.weight'].resize(1,256*256).numpy()\n",
    "wf_3=wf['4.weight'].resize(1,256*256).numpy()\n",
    "wf_4=wf['6.weight'].resize(1,256*256).numpy()\n",
    "wf_5=wf['8.weight'].resize(1,10*256).numpy()\n",
    "\n",
    "print('layer  1: linalg.norm value',LA.norm((w_reinit_l1-wf_0),np.inf), '; max(abs()) value',np.max(np.abs(w_reinit_l1-wf_0)))\n",
    "print('layer  2 linalg.norm value',LA.norm(w_reinit_l2-wf_2,np.inf),'; max(abs()) value',np.max(np.abs(w_reinit_l2-wf_2)))\n",
    "print('layer  3 linalg.norm value',LA.norm(w_reinit_l3-wf_3,np.inf),'; max(abs()) value',np.max(np.abs(w_reinit_l3-wf_3)))\n",
    "print('layer  4 linalg.norm value',LA.norm(w_reinit_l4-wf_4,np.inf),'; max(abs()) value',np.max(np.abs(w_reinit_l4-wf_4)))\n",
    "\n",
    "print('layer  5 linalg.norm value',LA.norm(w_reinit_l5-wf_5,np.inf),'; max(abs()) value',np.max(np.abs(w_reinit_l5-wf_5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

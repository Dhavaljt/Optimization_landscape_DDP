{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "128MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdODI2EZ_zT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "f4e70533-dc45-4cb6-e6c3-c0c86f34088b"
      },
      "source": [
        "!pip install q scipy==1.1.0\n",
        "#use an older version of scipy for executing sparse matrix operations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: q in /usr/local/lib/python3.6/dist-packages (2.6)\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLlo3RHGGmYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "e2256561-3edc-46ff-8faa-831844c98860"
      },
      "source": [
        "!pip install q scipy==1.1.0\n",
        "import numpy as np\n",
        "import torch \n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from time import time \n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn,optim \n",
        "from scipy.sparse.linalg import lsqr\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse import random\n",
        "from scipy.sparse import rand\n",
        "from scipy import stats\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: q in /usr/local/lib/python3.6/dist-packages (2.6)\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsymeQVTHyOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,)), ])\n",
        "trainset = datasets.MNIST('./',download = True, train = True, transform = transform)\n",
        "valset = datasets.MNIST('./',download= True, train= False, transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64,shuffle = True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size = 64, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRDdkde0H0my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzhQEnQShwHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "b3a3a523-ead6-4c74-838e-2a9d2c867d21"
      },
      "source": [
        "inputsize = 784\n",
        "hiddensizes = [128,128,128]\n",
        "outputsize = 10\n",
        "net = nn.Sequential(nn.Linear(inputsize,hiddensizes[0]),nn.ReLU(),nn.Linear(hiddensizes[0],hiddensizes[1]),nn.ReLU(),\n",
        "                    nn.Linear(hiddensizes[1],hiddensizes[2]),nn.ReLU(),nn.Linear(hiddensizes[2],outputsize),nn.LogSoftmax(dim=1))\n",
        "net.apply(init_weights)\n",
        "w_init= list(net.parameters())\n",
        "w_init[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 7.8869e-02,  5.6885e-02,  2.2825e-02,  ..., -5.7455e-02,\n",
              "          7.3772e-02,  4.3002e-02],\n",
              "        [-7.9931e-02,  1.8043e-03, -6.8392e-02,  ..., -1.2933e-02,\n",
              "         -1.7669e-02, -8.0947e-02],\n",
              "        [-7.1699e-02,  3.2029e-02, -3.1321e-03,  ..., -3.5651e-02,\n",
              "         -2.7409e-02,  5.7684e-02],\n",
              "        ...,\n",
              "        [-5.6637e-02, -4.1404e-02,  5.7319e-02,  ..., -3.0192e-02,\n",
              "         -6.6982e-02,  3.2356e-02],\n",
              "        [ 4.2089e-02,  1.2743e-02,  2.1949e-05,  ..., -8.0196e-03,\n",
              "         -6.3435e-02, -7.9036e-03],\n",
              "        [-3.0654e-02,  7.1574e-02,  4.4725e-02,  ...,  5.1446e-02,\n",
              "          2.7728e-02, -7.5360e-02]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYaH5VKJH3JL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "dd44611e-8851-4764-bce8-c1fef72dd3a3"
      },
      "source": [
        "#define the model \n",
        "#set random seed for reproducibility\n",
        "torch.manual_seed(0)\n",
        "inputsize = 784\n",
        "hiddensizes = [128,128,128]\n",
        "outputsize = 10\n",
        "net = nn.Sequential(nn.Linear(inputsize,hiddensizes[0]),nn.ReLU(),nn.Linear(hiddensizes[0],hiddensizes[1]),nn.ReLU(),\n",
        "                    nn.Linear(hiddensizes[1],hiddensizes[2]),nn.ReLU(),nn.Linear(hiddensizes[2],outputsize),nn.LogSoftmax(dim=1))\n",
        "net.apply(init_weights)\n",
        "w_init= list(net.parameters())\n",
        "torch.save(net.state_dict(),'weights_i.pth')\n",
        "print(net)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0],-1)\n",
        "logps = (net(images))\n",
        "loss = criterion(logps,labels)\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(),lr = 0.003, momentum = 0.9 )\n",
        "time0 = time()\n",
        "epochs =5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images,labels in trainloader:\n",
        "        images = images.view(images.shape[0],-1)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(images)\n",
        "        loss = criterion(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss+=loss.item()\n",
        "#     else:\n",
        "    print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "#     print(running_loss)\n",
        "            \n",
        "    print(\"\\n Training time in minutes = \", (time()-time0)/60)\n",
        "    \n",
        "    torch.save(net.state_dict(),'weights_f.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (7): LogSoftmax()\n",
            ")\n",
            "Epoch 0 - Training loss: 0.454596993582907\n",
            "\n",
            " Training time in minutes =  0.1601380427678426\n",
            "Epoch 1 - Training loss: 0.21611409411549187\n",
            "\n",
            " Training time in minutes =  0.3144444465637207\n",
            "Epoch 2 - Training loss: 0.1602034371223118\n",
            "\n",
            " Training time in minutes =  0.4776981115341187\n",
            "Epoch 3 - Training loss: 0.12960973877245302\n",
            "\n",
            " Training time in minutes =  0.6433154026667277\n",
            "Epoch 4 - Training loss: 0.11076642346900029\n",
            "\n",
            " Training time in minutes =  0.8025577108065287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKYg4dd6WHMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GelVDlYXICw0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "d9cbb322-174f-4bb8-dde2-14a3ace011a9"
      },
      "source": [
        "#testing\n",
        "correct_count, all_count = 0, 0\n",
        "for images,labels in valloader:\n",
        "    for i in range(len(labels)):\n",
        "        img = images[i].view(1, 784)\n",
        "        with torch.no_grad():\n",
        "            logps = net(img)\n",
        "\n",
        "    \n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.numpy()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.numpy()[i]\n",
        "        if(true_label == pred_label):\n",
        "              correct_count += 1\n",
        "        all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Images Tested = 10000\n",
            "\n",
            "Model Accuracy = 0.9639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-TImDIVIpRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "4800d8bf-2800-4a29-82f4-9f6879e96503"
      },
      "source": [
        "#Projecting weights on affine spaces defined by the set P: {AW = AW_final} \n",
        "#Projection is done using L2 minimization w= argmin ||w-w_initial|| in P\n",
        "\n",
        "#vectorize W\n",
        "wf =torch.load('weights_f.pth')\n",
        "wf1 = np.asarray(wf['0.weight'].resize(1,hiddensizes[0]*784))\n",
        "wf2 = np.asarray(wf['2.weight'].resize(1,hiddensizes[0]*hiddensizes[1]))\n",
        "wf3 = np.asarray(wf['4.weight'].resize(1,hiddensizes[1]*hiddensizes[2]))\n",
        "wf4 = np.asarray(wf['6.weight'].resize(1,hiddensizes[2]*10))\n",
        "wf_vec = np.concatenate((wf1,wf2,wf3,wf4),axis =1)\n",
        "wf_vec = wf_vec.T\n",
        "dim_w = wf_vec.shape[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuNMQNmql3Tp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9a64a276-28d0-494d-a5d0-2e2af1a4d34f"
      },
      "source": [
        "dim_w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVY9M3Hll0Tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "54f600a1-bd95-45d8-c27d-e619e631400c"
      },
      "source": [
        "#A run  1\n",
        "from scipy import sparse\n",
        "n_runs =2\n",
        "num_rows_arr  = np.asarray([2,4,8,16,32,64,128,256,512,1024,2048,4096,8192, 16384,32768,65536,131072,134400])\n",
        "den = 10/dim_w\n",
        "acc  = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_i = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_f = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "rvs = stats.norm().rvs\n",
        "\n",
        "wi = torch.load('weights_i.pth')\n",
        "wi1 = np.asarray(wi['0.weight'].resize(1,hiddensizes[0]*784))\n",
        "wi2 = np.asarray(wi['2.weight'].resize(1,hiddensizes[0]*hiddensizes[1]))\n",
        "wi3 = np.asarray(wi['4.weight'].resize(1,hiddensizes[1]*hiddensizes[2]))\n",
        "wi4 = np.asarray(wi['6.weight'].resize(1,hiddensizes[2]*10))\n",
        "w_init = np.concatenate((wi1,wi2,wi3,wi4), axis = 1)\n",
        "w_init = w_init.T\n",
        "\n",
        "w_init.ravel()\n",
        "w_init.squeeze()\n",
        "\n",
        "for i_out in range(n_runs):\n",
        "  print(\"outer iteration number:\",(i_out+1))\n",
        "  A_large = sparse.random(dim_w,dim_w, format='csr', density=den, data_rvs = rvs )\n",
        "\n",
        "  for i_in in range(num_rows_arr.shape[0]):\n",
        "      n_rows = num_rows_arr[i_in]\n",
        "      #minimize Z such that AZ = A(Wf-w_init)\n",
        "      A = A_large[0:n_rows,:]\n",
        "      w = np.zeros(dim_w)\n",
        "     \n",
        "\n",
        "      w_diff = csr_matrix(wf_vec - w_init)\n",
        "      b_eq = sparse.csr_matrix.dot(A,w_diff)\n",
        "\n",
        "      bn = b_eq.toarray()\n",
        "      bn.reshape((-1,))\n",
        "      \n",
        "      sol = lsqr(A,bn)\n",
        "      z = sol[0]\n",
        "      z = np.asmatrix(z).T\n",
        "      w = z+ w_init\n",
        "\n",
        "      #test performance of this reinitialization\n",
        "      w1= w[0:hiddensizes[0]*784]\n",
        "      w1 = w1.reshape(hiddensizes[0] , 784)\n",
        "      w2 = w[hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784]\n",
        "      w2 = w2.reshape(hiddensizes[1],hiddensizes[0])\n",
        "      w3 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]]\n",
        "      w3 = w3.reshape(hiddensizes[2],hiddensizes[1])\n",
        "      w4 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]: hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2] +hiddensizes[2]*10]\n",
        "      w4 = w4.reshape(10 , hiddensizes[2])\n",
        "\n",
        "      wf =torch.load('weights_f.pth')\n",
        "      wf['0.weight'] = torch.from_numpy(w1)\n",
        "      wf['2.weight'] = torch.from_numpy(w2)\n",
        "      wf['4.weight'] = torch.from_numpy(w3)\n",
        "      wf['6.weight'] = torch.from_numpy(w4)\n",
        "      torch.save(wf,'w_affex.pth')\n",
        "\n",
        "\n",
        "      net.load_state_dict(torch.load('w_affex.pth'))\n",
        "      #testing\n",
        "      correct_count, all_count = 0, 0\n",
        "      for images,labels in valloader:\n",
        "          for i in range(len(labels)):\n",
        "              img = images[i].view(1, 784)\n",
        "              with torch.no_grad():\n",
        "                  logps = net(img)\n",
        "\n",
        "\n",
        "              ps = torch.exp(logps)\n",
        "              probab = list(ps.numpy()[0])\n",
        "              pred_label = probab.index(max(probab))\n",
        "              true_label = labels.numpy()[i]\n",
        "              if(true_label == pred_label):\n",
        "                    correct_count += 1\n",
        "              all_count += 1\n",
        "\n",
        "      acc[i_out,i_in] = correct_count/all_count\n",
        "      dist_i[i_out,i_in] = np.linalg.norm(w-w_init)\n",
        "      dist_f[i_out,i_in] = np.linalg.norm(w-wf_vec)\n",
        "      print(\"\\n n_rows = {0} , Accuracy ={1}\".format(n_rows,acc[i_out,i_in]))\n",
        "      print(\"\\n Dist from Wi = {0} , Dist from Wf ={1}\".format(dist_i[i_out,i_in],dist_f[i_out,i_in]))    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "outer iteration number: 1\n",
            "\n",
            " n_rows = 2 , Accuracy =0.0916\n",
            "\n",
            " Dist from Wi = 0.025832757149639087 , Dist from Wf =6.40098835195938\n",
            "\n",
            " n_rows = 4 , Accuracy =0.0917\n",
            "\n",
            " Dist from Wi = 0.03684976624590671 , Dist from Wf =6.400934408973685\n",
            "\n",
            " n_rows = 8 , Accuracy =0.0916\n",
            "\n",
            " Dist from Wi = 0.040891594585081674 , Dist from Wf =6.400909864289846\n",
            "\n",
            " n_rows = 16 , Accuracy =0.0922\n",
            "\n",
            " Dist from Wi = 0.07667619678527925 , Dist from Wf =6.4005812215846944\n",
            "\n",
            " n_rows = 32 , Accuracy =0.092\n",
            "\n",
            " Dist from Wi = 0.09529803783627736 , Dist from Wf =6.400331045910312\n",
            "\n",
            " n_rows = 64 , Accuracy =0.0922\n",
            "\n",
            " Dist from Wi = 0.14052136505122295 , Dist from Wf =6.399497867741352\n",
            "\n",
            " n_rows = 128 , Accuracy =0.0926\n",
            "\n",
            " Dist from Wi = 0.19704959357418217 , Dist from Wf =6.398006773275962\n",
            "\n",
            " n_rows = 256 , Accuracy =0.096\n",
            "\n",
            " Dist from Wi = 0.2805389469042387 , Dist from Wf =6.394889921844501\n",
            "\n",
            " n_rows = 512 , Accuracy =0.0979\n",
            "\n",
            " Dist from Wi = 0.40489712607592526 , Dist from Wf =6.388221781554407\n",
            "\n",
            " n_rows = 1024 , Accuracy =0.1059\n",
            "\n",
            " Dist from Wi = 0.5802263320251975 , Dist from Wf =6.374688746669691\n",
            "\n",
            " n_rows = 2048 , Accuracy =0.1224\n",
            "\n",
            " Dist from Wi = 0.8176029305219299 , Dist from Wf =6.348609663596946\n",
            "\n",
            " n_rows = 4096 , Accuracy =0.1407\n",
            "\n",
            " Dist from Wi = 1.1253449877235955 , Dist from Wf =6.301342545106638\n",
            "\n",
            " n_rows = 8192 , Accuracy =0.1697\n",
            "\n",
            " Dist from Wi = 1.5712414381882371 , Dist from Wf =6.205201008570485\n",
            "\n",
            " n_rows = 16384 , Accuracy =0.288\n",
            "\n",
            " Dist from Wi = 2.2455339540151202 , Dist from Wf =5.994238606591517\n",
            "\n",
            " n_rows = 32768 , Accuracy =0.5563\n",
            "\n",
            " Dist from Wi = 3.177975180140071 , Dist from Wf =5.5564190743325215\n",
            "\n",
            " n_rows = 65536 , Accuracy =0.8944\n",
            "\n",
            " Dist from Wi = 4.481285687756876 , Dist from Wf =4.570710729215594\n",
            "\n",
            " n_rows = 131072 , Accuracy =0.9635\n",
            "\n",
            " Dist from Wi = 6.323468223560631 , Dist from Wf =0.9934068622617627\n",
            "\n",
            " n_rows = 134400 , Accuracy =0.9639\n",
            "\n",
            " Dist from Wi = 6.400141747526466 , Dist from Wf =0.09166693657027739\n",
            "outer iteration number: 2\n",
            "\n",
            " n_rows = 2 , Accuracy =0.0913\n",
            "\n",
            " Dist from Wi = 0.022497527982356325 , Dist from Wf =6.4010009431724955\n",
            "\n",
            " n_rows = 4 , Accuracy =0.0914\n",
            "\n",
            " Dist from Wi = 0.027116721267270175 , Dist from Wf =6.4009830414310755\n",
            "\n",
            " n_rows = 8 , Accuracy =0.0912\n",
            "\n",
            " Dist from Wi = 0.04177771614533562 , Dist from Wf =6.4009041420485095\n",
            "\n",
            " n_rows = 16 , Accuracy =0.0912\n",
            "\n",
            " Dist from Wi = 0.049418196079688746 , Dist from Wf =6.400849713526819\n",
            "\n",
            " n_rows = 32 , Accuracy =0.0918\n",
            "\n",
            " Dist from Wi = 0.07646091130963494 , Dist from Wf =6.400583796990385\n",
            "\n",
            " n_rows = 64 , Accuracy =0.0922\n",
            "\n",
            " Dist from Wi = 0.11671515432182981 , Dist from Wf =6.39997631135798\n",
            "\n",
            " n_rows = 128 , Accuracy =0.0945\n",
            "\n",
            " Dist from Wi = 0.15419462075745877 , Dist from Wf =6.3991830128655725\n",
            "\n",
            " n_rows = 256 , Accuracy =0.0956\n",
            "\n",
            " Dist from Wi = 0.23490079659893293 , Dist from Wf =6.396728916345778\n",
            "\n",
            " n_rows = 512 , Accuracy =0.0984\n",
            "\n",
            " Dist from Wi = 0.3496175222764861 , Dist from Wf =6.391485492547639\n",
            "\n",
            " n_rows = 1024 , Accuracy =0.0974\n",
            "\n",
            " Dist from Wi = 0.5074786340332509 , Dist from Wf =6.380892151450588\n",
            "\n",
            " n_rows = 2048 , Accuracy =0.1097\n",
            "\n",
            " Dist from Wi = 0.7598712325414019 , Dist from Wf =6.355778073687037\n",
            "\n",
            " n_rows = 4096 , Accuracy =0.1259\n",
            "\n",
            " Dist from Wi = 1.0713511450572164 , Dist from Wf =6.310746860302745\n",
            "\n",
            " n_rows = 8192 , Accuracy =0.1757\n",
            "\n",
            " Dist from Wi = 1.5359476150983244 , Dist from Wf =6.214031230513536\n",
            "\n",
            " n_rows = 16384 , Accuracy =0.285\n",
            "\n",
            " Dist from Wi = 2.223510295365992 , Dist from Wf =6.002442934022858\n",
            "\n",
            " n_rows = 32768 , Accuracy =0.6055\n",
            "\n",
            " Dist from Wi = 3.1794733187221924 , Dist from Wf =5.555561951949501\n",
            "\n",
            " n_rows = 65536 , Accuracy =0.8964\n",
            "\n",
            " Dist from Wi = 4.4785129868481794 , Dist from Wf =4.5734276568344665\n",
            "\n",
            " n_rows = 131072 , Accuracy =0.9618\n",
            "\n",
            " Dist from Wi = 6.321644762170569 , Dist from Wf =1.0050395885558892\n",
            "\n",
            " n_rows = 134400 , Accuracy =0.9639\n",
            "\n",
            " Dist from Wi = 6.400014685724974 , Dist from Wf =0.09581217060330115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cHK9SLwm69U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"accuracy_A.npy\", acc)\n",
        "np.save(\"distance_i_A.npy\", dist_i)\n",
        "np.save(\"distance_f_A.npy\", dist_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm6FWPGinFQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89c15808-9d00-460b-d9c9-ec67237524de"
      },
      "source": [
        "#winit, AI run 1\n",
        "I = sparse.identity(dim_w)\n",
        "n_runs =2\n",
        "num_rows_arr  = np.asarray([2,4,8,16,32,64,128,256,512,1024,2048,4096,8192, 16384,32768,65536,131072,134400])\n",
        "den = 10/dim_w\n",
        "acc  = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_i = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_f = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "rvs = stats.norm().rvs\n",
        "\n",
        "wi = torch.load('weights_i.pth')\n",
        "wi1 = np.asarray(wi['0.weight'].resize(1,hiddensizes[0]*784))\n",
        "wi2 = np.asarray(wi['2.weight'].resize(1,hiddensizes[0]*hiddensizes[1]))\n",
        "wi3 = np.asarray(wi['4.weight'].resize(1,hiddensizes[1]*hiddensizes[2]))\n",
        "wi4 = np.asarray(wi['6.weight'].resize(1,hiddensizes[2]*10))\n",
        "w_init = np.concatenate((wi1,wi2,wi3,wi4), axis = 1)\n",
        "w_init = w_init.T\n",
        "\n",
        "w_init.ravel()\n",
        "w_init.squeeze()\n",
        "\n",
        "for i_out in range(n_runs):\n",
        "  print(\"outer iteration number:\",(i_out+1))\n",
        "  A_large = sparse.random(dim_w,dim_w, format='csr', density=den, data_rvs = rvs ) + I\n",
        "\n",
        "  for i_in in range(num_rows_arr.shape[0]):\n",
        "      n_rows = num_rows_arr[i_in]\n",
        "      #minimize Z such that AZ = A(Wf-w_init)\n",
        "      A = A_large[0:n_rows,:] \n",
        "      w = np.zeros(dim_w)\n",
        "     \n",
        "\n",
        "      w_diff = csr_matrix(wf_vec - w_init)\n",
        "      b_eq = sparse.csr_matrix.dot(A,w_diff)\n",
        "\n",
        "      bn = b_eq.toarray()\n",
        "      bn.reshape((-1,))\n",
        "      \n",
        "      sol = lsqr(A,bn)\n",
        "      z = sol[0]\n",
        "      z = np.asmatrix(z).T\n",
        "      w = z+ w_init\n",
        "\n",
        "      #test performance of this reinitialization\n",
        "      w1= w[0:hiddensizes[0]*784]\n",
        "      w1 = w1.reshape(hiddensizes[0] , 784)\n",
        "      w2 = w[hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784]\n",
        "      w2 = w2.reshape(hiddensizes[1],hiddensizes[0])\n",
        "      w3 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]]\n",
        "      w3 = w3.reshape(hiddensizes[2],hiddensizes[1])\n",
        "      w4 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]: hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2] +hiddensizes[2]*10]\n",
        "      w4 = w4.reshape(10 , hiddensizes[2])\n",
        "\n",
        "      wf =torch.load('weights_f.pth')\n",
        "      wf['0.weight'] = torch.from_numpy(w1)\n",
        "      wf['2.weight'] = torch.from_numpy(w2)\n",
        "      wf['4.weight'] = torch.from_numpy(w3)\n",
        "      wf['6.weight'] = torch.from_numpy(w4)\n",
        "      torch.save(wf,'w_affex.pth')\n",
        "\n",
        "\n",
        "      net.load_state_dict(torch.load('w_affex.pth'))\n",
        "      #testing\n",
        "      correct_count, all_count = 0, 0\n",
        "      for images,labels in valloader:\n",
        "          for i in range(len(labels)):\n",
        "              img = images[i].view(1, 784)\n",
        "              with torch.no_grad():\n",
        "                  logps = net(img)\n",
        "\n",
        "\n",
        "              ps = torch.exp(logps)\n",
        "              probab = list(ps.numpy()[0])\n",
        "              pred_label = probab.index(max(probab))\n",
        "              true_label = labels.numpy()[i]\n",
        "              if(true_label == pred_label):\n",
        "                    correct_count += 1\n",
        "              all_count += 1\n",
        "\n",
        "      acc[i_out,i_in] = correct_count/all_count\n",
        "      dist_i[i_out,i_in] = np.linalg.norm(w-w_init)\n",
        "      dist_f[i_out,i_in] = np.linalg.norm(w-wf_vec)\n",
        "      print(\"\\n n_rows = {0} , Accuracy ={1}\".format(n_rows,acc[i_out,i_in]))\n",
        "      print(\"\\n Dist from Wi = {0} , Dist from Wf ={1}\".format(dist_i[i_out,i_in],dist_f[i_out,i_in]))    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "outer iteration number: 1\n",
            "\n",
            " n_rows = 2 , Accuracy =0.0917\n",
            "\n",
            " Dist from Wi = 0.014612138284833563 , Dist from Wf =6.401023800821358\n",
            "\n",
            " n_rows = 4 , Accuracy =0.0914\n",
            "\n",
            " Dist from Wi = 0.035277786157421165 , Dist from Wf =6.400943265727401\n",
            "\n",
            " n_rows = 8 , Accuracy =0.0916\n",
            "\n",
            " Dist from Wi = 0.06186766666165217 , Dist from Wf =6.400741488693242\n",
            "\n",
            " n_rows = 16 , Accuracy =0.0912\n",
            "\n",
            " Dist from Wi = 0.06687085516790518 , Dist from Wf =6.400691173769715\n",
            "\n",
            " n_rows = 32 , Accuracy =0.09\n",
            "\n",
            " Dist from Wi = 0.1015456340818575 , Dist from Wf =6.400234972057618\n",
            "\n",
            " n_rows = 64 , Accuracy =0.0901\n",
            "\n",
            " Dist from Wi = 0.13501070766692214 , Dist from Wf =6.399616498051188\n",
            "\n",
            " n_rows = 128 , Accuracy =0.0935\n",
            "\n",
            " Dist from Wi = 0.20310296592941965 , Dist from Wf =6.39781747147375\n",
            "\n",
            " n_rows = 256 , Accuracy =0.0972\n",
            "\n",
            " Dist from Wi = 0.3383802298575421 , Dist from Wf =6.392090271072322\n",
            "\n",
            " n_rows = 512 , Accuracy =0.102\n",
            "\n",
            " Dist from Wi = 0.47921013644179544 , Dist from Wf =6.3830773815433846\n",
            "\n",
            " n_rows = 1024 , Accuracy =0.1067\n",
            "\n",
            " Dist from Wi = 0.6279632629521117 , Dist from Wf =6.3701633695005535\n",
            "\n",
            " n_rows = 2048 , Accuracy =0.1216\n",
            "\n",
            " Dist from Wi = 0.8364860240818736 , Dist from Wf =6.346149253299502\n",
            "\n",
            " n_rows = 4096 , Accuracy =0.1491\n",
            "\n",
            " Dist from Wi = 1.135514638579536 , Dist from Wf =6.299517895854356\n",
            "\n",
            " n_rows = 8192 , Accuracy =0.196\n",
            "\n",
            " Dist from Wi = 1.556118668487184 , Dist from Wf =6.209010702413961\n",
            "\n",
            " n_rows = 16384 , Accuracy =0.3199\n",
            "\n",
            " Dist from Wi = 2.183720908336233 , Dist from Wf =6.017032674451948\n",
            "\n",
            " n_rows = 32768 , Accuracy =0.5891\n",
            "\n",
            " Dist from Wi = 3.1159242567179763 , Dist from Wf =5.591451979302327\n",
            "\n",
            " n_rows = 65536 , Accuracy =0.8859\n",
            "\n",
            " Dist from Wi = 4.434844208968873 , Dist from Wf =4.6157855285766285\n",
            "\n",
            " n_rows = 131072 , Accuracy =0.9602\n",
            "\n",
            " Dist from Wi = 6.319922063288199 , Dist from Wf =1.0158265012793455\n",
            "\n",
            " n_rows = 134400 , Accuracy =0.9639\n",
            "\n",
            " Dist from Wi = 6.400355424817463 , Dist from Wf =0.07501495076351035\n",
            "outer iteration number: 2\n",
            "\n",
            " n_rows = 2 , Accuracy =0.0916\n",
            "\n",
            " Dist from Wi = 0.014151889427210787 , Dist from Wf =6.401024834921838\n",
            "\n",
            " n_rows = 4 , Accuracy =0.0915\n",
            "\n",
            " Dist from Wi = 0.025726721957400948 , Dist from Wf =6.400988779012501\n",
            "\n",
            " n_rows = 8 , Accuracy =0.0913\n",
            "\n",
            " Dist from Wi = 0.03461949085401708 , Dist from Wf =6.4009468599666945\n",
            "\n",
            " n_rows = 16 , Accuracy =0.0911\n",
            "\n",
            " Dist from Wi = 0.07423164801396025 , Dist from Wf =6.40061003933974\n",
            "\n",
            " n_rows = 32 , Accuracy =0.0913\n",
            "\n",
            " Dist from Wi = 0.10097729742741589 , Dist from Wf =6.400243964002089\n",
            "\n",
            " n_rows = 64 , Accuracy =0.0908\n",
            "\n",
            " Dist from Wi = 0.14665196205944334 , Dist from Wf =6.399360312986359\n",
            "\n",
            " n_rows = 128 , Accuracy =0.0897\n",
            "\n",
            " Dist from Wi = 0.19849238726419663 , Dist from Wf =6.397962174436074\n",
            "\n",
            " n_rows = 256 , Accuracy =0.0963\n",
            "\n",
            " Dist from Wi = 0.31611447272113097 , Dist from Wf =6.393230079825199\n",
            "\n",
            " n_rows = 512 , Accuracy =0.1009\n",
            "\n",
            " Dist from Wi = 0.44355181639408237 , Dist from Wf =6.385654312576382\n",
            "\n",
            " n_rows = 1024 , Accuracy =0.1059\n",
            "\n",
            " Dist from Wi = 0.6258701716120213 , Dist from Wf =6.370369356789315\n",
            "\n",
            " n_rows = 2048 , Accuracy =0.1125\n",
            "\n",
            " Dist from Wi = 0.8344043387871948 , Dist from Wf =6.346423292925149\n",
            "\n",
            " n_rows = 4096 , Accuracy =0.139\n",
            "\n",
            " Dist from Wi = 1.1471954879537865 , Dist from Wf =6.297401188347567\n",
            "\n",
            " n_rows = 8192 , Accuracy =0.1794\n",
            "\n",
            " Dist from Wi = 1.6050402567872708 , Dist from Wf =6.196544600438024\n",
            "\n",
            " n_rows = 16384 , Accuracy =0.3034\n",
            "\n",
            " Dist from Wi = 2.2255622435712943 , Dist from Wf =6.001682423442329\n",
            "\n",
            " n_rows = 32768 , Accuracy =0.5862\n",
            "\n",
            " Dist from Wi = 3.118953488454728 , Dist from Wf =5.589762816653351\n",
            "\n",
            " n_rows = 65536 , Accuracy =0.8893\n",
            "\n",
            " Dist from Wi = 4.417873921859049 , Dist from Wf =4.63203078739166\n",
            "\n",
            " n_rows = 131072 , Accuracy =0.9629\n",
            "\n",
            " Dist from Wi = 6.3184190902959765 , Dist from Wf =1.0251334261587752\n",
            "\n",
            " n_rows = 134400 , Accuracy =0.9637\n",
            "\n",
            " Dist from Wi = 6.400289381306469 , Dist from Wf =0.08435138411919366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82ToSg3zp0VQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"accuracy_AI.npy\", acc)\n",
        "np.save(\"distance_i_AI.npy\", dist_i)\n",
        "np.save(\"distance_f_AI.npy\", dist_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq2gHKMJp3Xj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8009d0dc-2d46-446c-dc74-46a86e6f79ec"
      },
      "source": [
        "#I run 1\n",
        "from scipy import sparse\n",
        "n_runs =1\n",
        "num_rows_arr  = np.asarray([2,4,8,16,32,64,128,256,512,1024,2048,4096,8192, 16384,32768,65536,131072,784*128,784*128+128*128,784*128+128*128+128*128,784*128+128*128+128*128+1280])\n",
        "num_rows_arr = np.sort(num_rows_arr)\n",
        "den = 10/dim_w\n",
        "acc  = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_i = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_f = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "\n",
        "wi = torch.load('weights_i.pth')\n",
        "wi1 = np.asarray(wi['0.weight'].resize(1,hiddensizes[0]*784))\n",
        "wi2 = np.asarray(wi['2.weight'].resize(1,hiddensizes[0]*hiddensizes[1]))\n",
        "wi3 = np.asarray(wi['4.weight'].resize(1,hiddensizes[1]*hiddensizes[2]))\n",
        "wi4 = np.asarray(wi['6.weight'].resize(1,hiddensizes[2]*10))\n",
        "w_init = np.concatenate((wi1,wi2,wi3,wi4), axis = 1)\n",
        "w_init = w_init.T\n",
        "\n",
        "w_init.ravel()\n",
        "w_init.squeeze()\n",
        "\n",
        "for i_out in range(n_runs):\n",
        "  print(\"outer iteration number:\",(i_out+1))\n",
        "  for i_in in range(num_rows_arr.shape[0]):\n",
        "      n_rows = num_rows_arr[i_in]\n",
        "      #minimize Z such that AZ = A(Wf-w_init)\n",
        "      w = np.zeros((dim_w,1))\n",
        "      w[0:n_rows] = wf_vec[0:n_rows]\n",
        "      w[n_rows:] = w_init[n_rows:]\n",
        "\n",
        "      #test performance of this reinitialization\n",
        "      w1= w[0:hiddensizes[0]*784]\n",
        "      w1 = w1.reshape(hiddensizes[0] , 784)\n",
        "      w2 = w[hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784]\n",
        "      w2 = w2.reshape(hiddensizes[1],hiddensizes[0])\n",
        "      w3 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]]\n",
        "      w3 = w3.reshape(hiddensizes[2],hiddensizes[1])\n",
        "      w4 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]: hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2] +hiddensizes[2]*10]\n",
        "      w4 = w4.reshape(10 , hiddensizes[2])\n",
        "\n",
        "      wf =torch.load('weights_f.pth')\n",
        "      wf['0.weight'] = torch.from_numpy(w1)\n",
        "      wf['2.weight'] = torch.from_numpy(w2)\n",
        "      wf['4.weight'] = torch.from_numpy(w3)\n",
        "      wf['6.weight'] = torch.from_numpy(w4)\n",
        "      torch.save(wf,'w_affex.pth')\n",
        "\n",
        "\n",
        "      net.load_state_dict(torch.load('w_affex.pth'))\n",
        "      #testing\n",
        "      correct_count, all_count = 0, 0\n",
        "      for images,labels in valloader:\n",
        "          for i in range(len(labels)):\n",
        "              img = images[i].view(1, 784)\n",
        "              with torch.no_grad():\n",
        "                  logps = net(img)\n",
        "\n",
        "\n",
        "              ps = torch.exp(logps)\n",
        "              probab = list(ps.numpy()[0])\n",
        "              pred_label = probab.index(max(probab))\n",
        "              true_label = labels.numpy()[i]\n",
        "              if(true_label == pred_label):\n",
        "                    correct_count += 1\n",
        "              all_count += 1\n",
        "\n",
        "      acc[i_out,i_in] = correct_count/all_count\n",
        "      dist_i[i_out,i_in] = np.linalg.norm(w-w_init)\n",
        "      dist_f[i_out,i_in] = np.linalg.norm(w-wf_vec)\n",
        "      print(\"\\n n_rows = {0} , Accuracy ={1}\".format(n_rows,acc[i_out,i_in]))\n",
        "      print(\"\\n Dist from Wi = {0} , Dist from Wf ={1}\".format(dist_i[i_out,i_in],dist_f[i_out,i_in]))    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "outer iteration number: 1\n",
            "\n",
            " n_rows = 2 , Accuracy =0.0916\n",
            "\n",
            " Dist from Wi = 0.0025935853493631094 , Dist from Wf =6.401039953521266\n",
            "\n",
            " n_rows = 4 , Accuracy =0.0915\n",
            "\n",
            " Dist from Wi = 0.0036679245540393586 , Dist from Wf =6.40103942806088\n",
            "\n",
            " n_rows = 8 , Accuracy =0.0915\n",
            "\n",
            " Dist from Wi = 0.005187220747449995 , Dist from Wf =6.401038377169865\n",
            "\n",
            " n_rows = 16 , Accuracy =0.0909\n",
            "\n",
            " Dist from Wi = 0.0072451247687326265 , Dist from Wf =6.401036378698967\n",
            "\n",
            " n_rows = 32 , Accuracy =0.0903\n",
            "\n",
            " Dist from Wi = 0.010310484417144281 , Dist from Wf =6.4010321751395365\n",
            "\n",
            " n_rows = 64 , Accuracy =0.0889\n",
            "\n",
            " Dist from Wi = 0.014423851323990254 , Dist from Wf =6.40102422786959\n",
            "\n",
            " n_rows = 128 , Accuracy =0.0893\n",
            "\n",
            " Dist from Wi = 0.14437136875126969 , Dist from Wf =6.399412169968847\n",
            "\n",
            " n_rows = 256 , Accuracy =0.1087\n",
            "\n",
            " Dist from Wi = 0.501429982009391 , Dist from Wf =6.381370321992179\n",
            "\n",
            " n_rows = 512 , Accuracy =0.1127\n",
            "\n",
            " Dist from Wi = 0.7717346311182466 , Dist from Wf =6.354348501018283\n",
            "\n",
            " n_rows = 1024 , Accuracy =0.1146\n",
            "\n",
            " Dist from Wi = 0.8656768464586642 , Dist from Wf =6.342233266820599\n",
            "\n",
            " n_rows = 2048 , Accuracy =0.1114\n",
            "\n",
            " Dist from Wi = 1.0575277785267536 , Dist from Wf =6.3130780298444575\n",
            "\n",
            " n_rows = 4096 , Accuracy =0.126\n",
            "\n",
            " Dist from Wi = 1.2298427060507877 , Dist from Wf =6.281783674374197\n",
            "\n",
            " n_rows = 8192 , Accuracy =0.1418\n",
            "\n",
            " Dist from Wi = 1.5759873696900555 , Dist from Wf =6.203997342346137\n",
            "\n",
            " n_rows = 16384 , Accuracy =0.2119\n",
            "\n",
            " Dist from Wi = 1.9780509719170365 , Dist from Wf =6.0877445384771685\n",
            "\n",
            " n_rows = 32768 , Accuracy =0.3215\n",
            "\n",
            " Dist from Wi = 2.7863701190554018 , Dist from Wf =5.762765028429989\n",
            "\n",
            " n_rows = 65536 , Accuracy =0.4306\n",
            "\n",
            " Dist from Wi = 3.885396875475269 , Dist from Wf =5.086945088489507\n",
            "\n",
            " n_rows = 100352 , Accuracy =0.5529\n",
            "\n",
            " Dist from Wi = 4.894982513857665 , Dist from Wf =4.124617000678755\n",
            "\n",
            " n_rows = 116736 , Accuracy =0.809\n",
            "\n",
            " Dist from Wi = 5.515873990423666 , Dist from Wf =3.2478382556753487\n",
            "\n",
            " n_rows = 131072 , Accuracy =0.9357\n",
            "\n",
            " Dist from Wi = 5.9892333801842295 , Dist from Wf =2.258849869058923\n",
            "\n",
            " n_rows = 133120 , Accuracy =0.9412\n",
            "\n",
            " Dist from Wi = 6.04871852078518 , Dist from Wf =2.0943551440887145\n",
            "\n",
            " n_rows = 134400 , Accuracy =0.9639\n",
            "\n",
            " Dist from Wi = 6.401040478958128 , Dist from Wf =0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sfApRl8sjqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"accuracy_I.npy\", acc)\n",
        "np.save(\"distance_i_I.npy\", dist_i)\n",
        "np.save(\"distance_f_I.npy\", dist_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmwwSQ9ysmfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56025c44-283e-4734-f636-f0f45d70a3d9"
      },
      "source": [
        "# A=Irev run number 3  \n",
        "from scipy import sparse\n",
        "\n",
        "n_runs =1\n",
        "num_rows_arr  = np.asarray([2,4,8,16,32,64,128,256,512,1024,2048,4096,8192, 16384,32768,65536,131072,784*128,784*128+128*128,784*128+128*128+128*128,784*128+128*128+128*128+1280])\n",
        "num_rows_arr = np.sort(num_rows_arr)\n",
        "\n",
        "den = 10/dim_w\n",
        "acc  = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_i = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_f = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "rvs = stats.norm().rvs\n",
        "\n",
        "wi = torch.load('weights_i.pth')\n",
        "wi1 = np.asarray(wi['0.weight'].resize(1,hiddensizes[0]*784))\n",
        "wi2 = np.asarray(wi['2.weight'].resize(1,hiddensizes[0]*hiddensizes[1]))\n",
        "wi3 = np.asarray(wi['4.weight'].resize(1,hiddensizes[1]*hiddensizes[2]))\n",
        "wi4 = np.asarray(wi['6.weight'].resize(1,hiddensizes[2]*10))\n",
        "w_init = np.concatenate((wi1,wi2,wi3,wi4), axis = 1)\n",
        "w_init = w_init.T\n",
        "\n",
        "w_init.ravel()\n",
        "w_init.squeeze()\n",
        "\n",
        "for i_out in range(n_runs):\n",
        "  print(\"outer iteration number:\",(i_out+1))\n",
        "  for i_in in range(num_rows_arr.shape[0]):\n",
        "      n_rows = num_rows_arr[i_in]\n",
        "      #minimize Z such that AZ = A(Wf-w_init)\n",
        "      w = np.zeros((dim_w,1))\n",
        "      w[0:-n_rows] = w_init[0:-n_rows]\n",
        "      w[-n_rows:] = wf_vec[-n_rows:] \n",
        "\n",
        "      #test performance of this reinitialization\n",
        "      w1= w[0:hiddensizes[0]*784]\n",
        "      w1 = w1.reshape(hiddensizes[0] , 784)\n",
        "      w2 = w[hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784]\n",
        "      w2 = w2.reshape(hiddensizes[1],hiddensizes[0])\n",
        "      w3 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]]\n",
        "      w3 = w3.reshape(hiddensizes[2],hiddensizes[1])\n",
        "      w4 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]: hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2] +hiddensizes[2]*10]\n",
        "      w4 = w4.reshape(10 , hiddensizes[2])\n",
        "\n",
        "      wf =torch.load('weights_f.pth')\n",
        "      wf['0.weight'] = torch.from_numpy(w1)\n",
        "      wf['2.weight'] = torch.from_numpy(w2)\n",
        "      wf['4.weight'] = torch.from_numpy(w3)\n",
        "      wf['6.weight'] = torch.from_numpy(w4)\n",
        "      torch.save(wf,'w_affex.pth')\n",
        "\n",
        "\n",
        "      net.load_state_dict(torch.load('w_affex.pth'))\n",
        "      #testing\n",
        "      correct_count, all_count = 0, 0\n",
        "      for images,labels in valloader:\n",
        "          for i in range(len(labels)):\n",
        "              img = images[i].view(1, 784)\n",
        "              with torch.no_grad():\n",
        "                  logps = net(img)\n",
        "\n",
        "\n",
        "              ps = torch.exp(logps)\n",
        "              probab = list(ps.numpy()[0])\n",
        "              pred_label = probab.index(max(probab))\n",
        "              true_label = labels.numpy()[i]\n",
        "              if(true_label == pred_label):\n",
        "                    correct_count += 1\n",
        "              all_count += 1\n",
        "\n",
        "      acc[i_out,i_in] = correct_count/all_count\n",
        "      dist_i[i_out,i_in] = np.linalg.norm(w-w_init)\n",
        "      dist_f[i_out,i_in] = np.linalg.norm(w-wf_vec)\n",
        "      print(\"\\n n_rows = {0} , Accuracy ={1}\".format(n_rows,acc[i_out,i_in]))\n",
        "      print(\"\\n Dist from Wi = {0} , Dist from Wf ={1}\".format(dist_i[i_out,i_in],dist_f[i_out,i_in]))    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "outer iteration number: 1\n",
            "\n",
            " n_rows = 2 , Accuracy =0.0916\n",
            "\n",
            " Dist from Wi = 0.10228690160097022 , Dist from Wf =6.400223168220103\n",
            "\n",
            " n_rows = 4 , Accuracy =0.0916\n",
            "\n",
            " Dist from Wi = 0.1148765831933198 , Dist from Wf =6.4000095768595795\n",
            "\n",
            " n_rows = 8 , Accuracy =0.0916\n",
            "\n",
            " Dist from Wi = 0.1316354506385036 , Dist from Wf =6.399686814321128\n",
            "\n",
            " n_rows = 16 , Accuracy =0.0916\n",
            "\n",
            " Dist from Wi = 0.29064334831246663 , Dist from Wf =6.394438650682499\n",
            "\n",
            " n_rows = 32 , Accuracy =0.0908\n",
            "\n",
            " Dist from Wi = 0.43393762728252994 , Dist from Wf =6.386314848869332\n",
            "\n",
            " n_rows = 64 , Accuracy =0.0921\n",
            "\n",
            " Dist from Wi = 0.5835393940382239 , Dist from Wf =6.374386322530665\n",
            "\n",
            " n_rows = 128 , Accuracy =0.0903\n",
            "\n",
            " Dist from Wi = 0.7576553987839039 , Dist from Wf =6.356042598185926\n",
            "\n",
            " n_rows = 256 , Accuracy =0.0904\n",
            "\n",
            " Dist from Wi = 1.0445383082904705 , Dist from Wf =6.3152402120405675\n",
            "\n",
            " n_rows = 512 , Accuracy =0.1032\n",
            "\n",
            " Dist from Wi = 1.403636588591378 , Dist from Wf =6.245248076772296\n",
            "\n",
            " n_rows = 1024 , Accuracy =0.1545\n",
            "\n",
            " Dist from Wi = 1.934838336051536 , Dist from Wf =6.101616165132467\n",
            "\n",
            " n_rows = 2048 , Accuracy =0.1803\n",
            "\n",
            " Dist from Wi = 2.1253434220223184 , Dist from Wf =6.037899846115947\n",
            "\n",
            " n_rows = 4096 , Accuracy =0.19\n",
            "\n",
            " Dist from Wi = 2.316509759419079 , Dist from Wf =5.967168654209187\n",
            "\n",
            " n_rows = 8192 , Accuracy =0.2299\n",
            "\n",
            " Dist from Wi = 2.652586263908148 , Dist from Wf =5.825556224583741\n",
            "\n",
            " n_rows = 16384 , Accuracy =0.2554\n",
            "\n",
            " Dist from Wi = 3.1912639778963476 , Dist from Wf =5.548797476628766\n",
            "\n",
            " n_rows = 32768 , Accuracy =0.3866\n",
            "\n",
            " Dist from Wi = 4.056340725892859 , Dist from Wf =4.951708707983891\n",
            "\n",
            " n_rows = 65536 , Accuracy =0.7444\n",
            "\n",
            " Dist from Wi = 5.01540146231239 , Dist from Wf =3.977319120349189\n",
            "\n",
            " n_rows = 100352 , Accuracy =0.9378\n",
            "\n",
            " Dist from Wi = 5.758561533331108 , Dist from Wf =2.7950470980110116\n",
            "\n",
            " n_rows = 116736 , Accuracy =0.9487\n",
            "\n",
            " Dist from Wi = 6.072479863985421 , Dist from Wf =2.024427700549497\n",
            "\n",
            " n_rows = 131072 , Accuracy =0.9605\n",
            "\n",
            " Dist from Wi = 6.299528408479943 , Dist from Wf =1.1354563153264285\n",
            "\n",
            " n_rows = 133120 , Accuracy =0.9641\n",
            "\n",
            " Dist from Wi = 6.337669019606453 , Dist from Wf =0.8984823933617602\n",
            "\n",
            " n_rows = 134400 , Accuracy =0.9639\n",
            "\n",
            " Dist from Wi = 6.401040478958128 , Dist from Wf =0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WG6aW44szXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"accuracy_UI.npy\", acc)\n",
        "np.save(\"distance_i_UI.npy\", dist_i)\n",
        "np.save(\"distance_f_UI.npy\", dist_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC0trhdIGrSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I and UI section to be added to the report MNIST128here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B4qKGlHPIoc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "e140f507-68e9-4cb2-b1a8-26b4d58faa2e"
      },
      "source": [
        "!pip install q scipy==1.1.0\n",
        "import numpy as np\n",
        "import torch \n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from time import time \n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn,optim \n",
        "from scipy.sparse.linalg import lsqr\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse import random\n",
        "from scipy.sparse import rand\n",
        "from scipy import stats\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: q in /usr/local/lib/python3.6/dist-packages (2.6)\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hts0xhtuD6xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,)), ])\n",
        "trainset = datasets.MNIST('./',download = True, train = True, transform = transform)\n",
        "valset = datasets.MNIST('./',download= True, train= False, transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64,shuffle = True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size = 64, shuffle = True)\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "\n",
        "#define the model \n",
        "inputsize = 784\n",
        "hiddensizes = [128,128,128]\n",
        "outputsize = 10\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0],-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIHT4_7vFONw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f73e8c6c-68fb-401c-ff63-909d9ccb8562"
      },
      "source": [
        "#Rerun for randomizing w_init\n",
        "\n",
        "net = nn.Sequential(nn.Linear(inputsize,hiddensizes[0]),nn.ReLU(),nn.Linear(hiddensizes[0],hiddensizes[1]),nn.ReLU(),\n",
        "                    nn.Linear(hiddensizes[1],hiddensizes[2]),nn.ReLU(),nn.Linear(hiddensizes[2],outputsize),nn.LogSoftmax(dim=1))\n",
        "net.apply(init_weights)\n",
        "\n",
        "w_init= list(net.parameters())\n",
        "torch.save(net.state_dict(),'weights_i.pth')\n",
        "\n",
        "print(net)\n",
        "logps = (net(images))\n",
        "loss = criterion(logps,labels)\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(),lr = 0.003, momentum = 0.9 )\n",
        "time0 = time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (7): LogSoftmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxEf7aTqFROX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "outputId": "a0b74835-bd77-4a59-b938-9b00288f9f03"
      },
      "source": [
        "epochs =15\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images,labels in trainloader:\n",
        "        images = images.view(images.shape[0],-1)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(images)\n",
        "        loss = criterion(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss+=loss.item()\n",
        "#     else:\n",
        "    print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "#     print(running_loss)\n",
        "            \n",
        "    print(\"\\n Training time in minutes = \", (time()-time0)/60)\n",
        "    \n",
        "    torch.save(net.state_dict(),'weights_f.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - Training loss: 0.435463518444409\n",
            "\n",
            " Training time in minutes =  0.15306503375371297\n",
            "Epoch 1 - Training loss: 0.21181978328999426\n",
            "\n",
            " Training time in minutes =  0.30463809967041017\n",
            "Epoch 2 - Training loss: 0.1616667501334506\n",
            "\n",
            " Training time in minutes =  0.45702494780222574\n",
            "Epoch 3 - Training loss: 0.1318252895102858\n",
            "\n",
            " Training time in minutes =  0.6036313454310099\n",
            "Epoch 4 - Training loss: 0.11256090790204117\n",
            "\n",
            " Training time in minutes =  0.7596362471580506\n",
            "Epoch 5 - Training loss: 0.0970835502404394\n",
            "\n",
            " Training time in minutes =  0.9081552624702454\n",
            "Epoch 6 - Training loss: 0.08550892844955042\n",
            "\n",
            " Training time in minutes =  1.0666768431663514\n",
            "Epoch 7 - Training loss: 0.07560704718095693\n",
            "\n",
            " Training time in minutes =  1.2263810873031615\n",
            "Epoch 8 - Training loss: 0.06973307509087463\n",
            "\n",
            " Training time in minutes =  1.3808390935262045\n",
            "Epoch 9 - Training loss: 0.060990888451629165\n",
            "\n",
            " Training time in minutes =  1.5300189852714539\n",
            "Epoch 10 - Training loss: 0.05444923504047207\n",
            "\n",
            " Training time in minutes =  1.6741903026898701\n",
            "Epoch 11 - Training loss: 0.04951680328489454\n",
            "\n",
            " Training time in minutes =  1.8312849442164103\n",
            "Epoch 12 - Training loss: 0.04623484441405857\n",
            "\n",
            " Training time in minutes =  1.9810166200002035\n",
            "Epoch 13 - Training loss: 0.04074844612870544\n",
            "\n",
            " Training time in minutes =  2.122456502914429\n",
            "Epoch 14 - Training loss: 0.03706987154819488\n",
            "\n",
            " Training time in minutes =  2.278580737113953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pP93J2uFUzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "78128e33-93f7-4e5d-e434-f7490fea40bb"
      },
      "source": [
        "#Projecting weights on affine spaces defined by the set P: {AW = AW_final} \n",
        "#Projection is done using L2 minimization w= argmin ||w-w_initial|| in P\n",
        "\n",
        "#vectorize W\n",
        "wf =torch.load('weights_f.pth')\n",
        "wf1 = np.asarray(wf['0.weight'].resize(1,hiddensizes[0]*784))\n",
        "wf2 = np.asarray(wf['2.weight'].resize(1,hiddensizes[0]*hiddensizes[1]))\n",
        "wf3 = np.asarray(wf['4.weight'].resize(1,hiddensizes[1]*hiddensizes[2]))\n",
        "wf4 = np.asarray(wf['6.weight'].resize(1,hiddensizes[2]*10))\n",
        "wf_vec = np.concatenate((wf1,wf2,wf3,wf4),axis =1)\n",
        "wf_vec = wf_vec.T\n",
        "dim_w = wf_vec.shape[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GmiyCK8nYX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "43c12916-835b-40f7-f113-19cbc5464dbc"
      },
      "source": [
        "dim_w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDIqe1EGFYA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "28a5056b-b411-49e3-c482-fe81489f79ad"
      },
      "source": [
        "#testing\n",
        "correct_count, all_count = 0, 0\n",
        "for images,labels in valloader:\n",
        "    for i in range(len(labels)):\n",
        "        img = images[i].view(1, 784)\n",
        "        with torch.no_grad():\n",
        "            logps = net(img)\n",
        "\n",
        "\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.numpy()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.numpy()[i]\n",
        "        if(true_label == pred_label):\n",
        "              correct_count += 1\n",
        "        all_count += 1\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))\n",
        "np.save('model_accuracy3.npy',(correct_count/all_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Images Tested = 10000\n",
            "\n",
            "Model Accuracy = 0.9758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8OqUGYTGT4E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae434481-7143-4340-e8a9-3d37e8929e7e"
      },
      "source": [
        "#I run 1\n",
        "from scipy import sparse\n",
        "n_runs =1\n",
        "num_rows_arr  = np.asarray([2,4,8,16,32,64,128,256,512,1024,2048,4096,8192, 16384,32768,65536,131072,262144,784*128,784*128+128*128,784*128+128*128+128*128,784*128+128*128+128*128+1280])\n",
        "num_rows_arr = np.sort(num_rows_arr)\n",
        "den = 10/dim_w\n",
        "acc  = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_i = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_f = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "\n",
        "wi = torch.load('weights_i.pth')\n",
        "wi1 = np.asarray(wi['0.weight'].resize(1,hiddensizes[0]*784))\n",
        "wi2 = np.asarray(wi['2.weight'].resize(1,hiddensizes[0]*hiddensizes[1]))\n",
        "wi3 = np.asarray(wi['4.weight'].resize(1,hiddensizes[1]*hiddensizes[2]))\n",
        "wi4 = np.asarray(wi['6.weight'].resize(1,hiddensizes[2]*10))\n",
        "w_init = np.concatenate((wi1,wi2,wi3,wi4), axis = 1)\n",
        "w_init = w_init.T\n",
        "\n",
        "w_init.ravel()\n",
        "w_init.squeeze()\n",
        "\n",
        "for i_out in range(n_runs):\n",
        "  print(\"outer iteration number:\",(i_out+1))\n",
        "  for i_in in range(num_rows_arr.shape[0]):\n",
        "      n_rows = num_rows_arr[i_in]\n",
        "      #minimize Z such that AZ = A(Wf-w_init)\n",
        "      w = np.zeros((dim_w,1))\n",
        "      w[0:n_rows] = wf_vec[0:n_rows]\n",
        "      w[n_rows:] = w_init[n_rows:]\n",
        "\n",
        "      #test performance of this reinitialization\n",
        "      w1= w[0:hiddensizes[0]*784]\n",
        "      w1 = w1.reshape(hiddensizes[0] , 784)\n",
        "      w2 = w[hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784]\n",
        "      w2 = w2.reshape(hiddensizes[1],hiddensizes[0])\n",
        "      w3 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]]\n",
        "      w3 = w3.reshape(hiddensizes[2],hiddensizes[1])\n",
        "      w4 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]: hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2] +hiddensizes[2]*10]\n",
        "      w4 = w4.reshape(10 , hiddensizes[2])\n",
        "\n",
        "      wf =torch.load('weights_f.pth')\n",
        "      wf['0.weight'] = torch.from_numpy(w1)\n",
        "      wf['2.weight'] = torch.from_numpy(w2)\n",
        "      wf['4.weight'] = torch.from_numpy(w3)\n",
        "      wf['6.weight'] = torch.from_numpy(w4)\n",
        "      torch.save(wf,'w_affex.pth')\n",
        "\n",
        "\n",
        "      net.load_state_dict(torch.load('w_affex.pth'))\n",
        "      #testing\n",
        "      correct_count, all_count = 0, 0\n",
        "      for images,labels in valloader:\n",
        "          for i in range(len(labels)):\n",
        "              img = images[i].view(1, 784)\n",
        "              with torch.no_grad():\n",
        "                  logps = net(img)\n",
        "\n",
        "\n",
        "              ps = torch.exp(logps)\n",
        "              probab = list(ps.numpy()[0])\n",
        "              pred_label = probab.index(max(probab))\n",
        "              true_label = labels.numpy()[i]\n",
        "              if(true_label == pred_label):\n",
        "                    correct_count += 1\n",
        "              all_count += 1\n",
        "\n",
        "      acc[i_out,i_in] = correct_count/all_count\n",
        "      dist_i[i_out,i_in] = np.linalg.norm(w-w_init)\n",
        "      dist_f[i_out,i_in] = np.linalg.norm(w-wf_vec)\n",
        "      print(\"\\n n_rows = {0} , Accuracy ={1}\".format(n_rows,acc[i_out,i_in]))\n",
        "      print(\"\\n Dist from Wi = {0} , Dist from Wf ={1}\".format(dist_i[i_out,i_in],dist_f[i_out,i_in]))    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outer iteration number: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " n_rows = 2 , Accuracy =0.1049\n",
            "\n",
            " Dist from Wi = 0.0047616034309549615 , Dist from Wf =9.156715864838445\n",
            "\n",
            " n_rows = 4 , Accuracy =0.1049\n",
            "\n",
            " Dist from Wi = 0.006734024734172078 , Dist from Wf =9.15671462671859\n",
            "\n",
            " n_rows = 8 , Accuracy =0.105\n",
            "\n",
            " Dist from Wi = 0.00952350008190671 , Dist from Wf =9.156712150395332\n",
            "\n",
            " n_rows = 16 , Accuracy =0.1046\n",
            "\n",
            " Dist from Wi = 0.013529444962984347 , Dist from Wf =9.156707107709098\n",
            "\n",
            " n_rows = 32 , Accuracy =0.104\n",
            "\n",
            " Dist from Wi = 0.019090258242915714 , Dist from Wf =9.156697202828733\n",
            "\n",
            " n_rows = 64 , Accuracy =0.1039\n",
            "\n",
            " Dist from Wi = 0.03067321538216925 , Dist from Wf =9.15666572809718\n",
            "\n",
            " n_rows = 128 , Accuracy =0.1046\n",
            "\n",
            " Dist from Wi = 0.12368738234605282 , Dist from Wf =9.155881690678385\n",
            "\n",
            " n_rows = 256 , Accuracy =0.1046\n",
            "\n",
            " Dist from Wi = 0.2716220022124977 , Dist from Wf =9.152687561048142\n",
            "\n",
            " n_rows = 512 , Accuracy =0.1072\n",
            "\n",
            " Dist from Wi = 0.5293863978412934 , Dist from Wf =9.141401322774968\n",
            "\n",
            " n_rows = 1024 , Accuracy =0.1046\n",
            "\n",
            " Dist from Wi = 0.7568999767114591 , Dist from Wf =9.12538056891358\n",
            "\n",
            " n_rows = 2048 , Accuracy =0.1065\n",
            "\n",
            " Dist from Wi = 1.0828363997945962 , Dist from Wf =9.092465751023273\n",
            "\n",
            " n_rows = 4096 , Accuracy =0.1224\n",
            "\n",
            " Dist from Wi = 1.4729652276540475 , Dist from Wf =9.037468757366378\n",
            "\n",
            " n_rows = 8192 , Accuracy =0.1226\n",
            "\n",
            " Dist from Wi = 1.9662096696759757 , Dist from Wf =8.943125160542259\n",
            "\n",
            " n_rows = 16384 , Accuracy =0.1596\n",
            "\n",
            " Dist from Wi = 2.9500305508742652 , Dist from Wf =8.668493978261727\n",
            "\n",
            " n_rows = 32768 , Accuracy =0.2521\n",
            "\n",
            " Dist from Wi = 4.268367435967903 , Dist from Wf =8.101018919482913\n",
            "\n",
            " n_rows = 65536 , Accuracy =0.3923\n",
            "\n",
            " Dist from Wi = 5.743206792907412 , Dist from Wf =7.13169291516071\n",
            "\n",
            " n_rows = 100352 , Accuracy =0.522\n",
            "\n",
            " Dist from Wi = 6.837773087514296 , Dist from Wf =6.090182863093401\n",
            "\n",
            " n_rows = 116736 , Accuracy =0.6895\n",
            "\n",
            " Dist from Wi = 7.805668426694545 , Dist from Wf =4.787171243516921\n",
            "\n",
            " n_rows = 131072 , Accuracy =0.9319\n",
            "\n",
            " Dist from Wi = 8.50727357681784 , Dist from Wf =3.3869993196675385\n",
            "\n",
            " n_rows = 133120 , Accuracy =0.9367\n",
            "\n",
            " Dist from Wi = 8.60195057996061 , Dist from Wf =3.138775927358734\n",
            "\n",
            " n_rows = 134400 , Accuracy =0.9758\n",
            "\n",
            " Dist from Wi = 9.156717102884162 , Dist from Wf =0.0\n",
            "\n",
            " n_rows = 262144 , Accuracy =0.9758\n",
            "\n",
            " Dist from Wi = 9.156717102884162 , Dist from Wf =0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwKYl93OKFl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"accuracy_I3.npy\", acc)\n",
        "np.save(\"distance_i_I3.npy\", dist_i)\n",
        "np.save(\"distance_f_I3.npy\", dist_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnLsCit2BxWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6456ca4e-e633-47d1-dac7-9c41f8b6b5c3"
      },
      "source": [
        "# A=Irev run number 3  \n",
        "from scipy import sparse\n",
        "\n",
        "n_runs =1\n",
        "num_rows_arr  = np.asarray([2,4,8,16,32,64,128,256,512,1024,2048,4096,8192, 16384,32768,65536,131072,262144,784*128,784*128+128*128,784*128+128*128+128*128,784*128+128*128+128*128+1280])\n",
        "num_rows_arr = np.sort(num_rows_arr)\n",
        "\n",
        "den = 10/dim_w\n",
        "acc  = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_i = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_f = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "rvs = stats.norm().rvs\n",
        "\n",
        "wi = torch.load('weights_i.pth')\n",
        "wi1 = np.asarray(wi['0.weight'].resize(1,hiddensizes[0]*784))\n",
        "wi2 = np.asarray(wi['2.weight'].resize(1,hiddensizes[0]*hiddensizes[1]))\n",
        "wi3 = np.asarray(wi['4.weight'].resize(1,hiddensizes[1]*hiddensizes[2]))\n",
        "wi4 = np.asarray(wi['6.weight'].resize(1,hiddensizes[2]*10))\n",
        "w_init = np.concatenate((wi1,wi2,wi3,wi4), axis = 1)\n",
        "w_init = w_init.T\n",
        "\n",
        "w_init.ravel()\n",
        "w_init.squeeze()\n",
        "\n",
        "for i_out in range(n_runs):\n",
        "  print(\"outer iteration number:\",(i_out+1))\n",
        "  for i_in in range(num_rows_arr.shape[0]):\n",
        "      n_rows = num_rows_arr[i_in]\n",
        "      #minimize Z such that AZ = A(Wf-w_init)\n",
        "      w = np.zeros((dim_w,1))\n",
        "      w[0:-n_rows] = w_init[0:-n_rows]\n",
        "      w[-n_rows:] = wf_vec[-n_rows:] \n",
        "\n",
        "      #test performance of this reinitialization\n",
        "      w1= w[0:hiddensizes[0]*784]\n",
        "      w1 = w1.reshape(hiddensizes[0] , 784)\n",
        "      w2 = w[hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784]\n",
        "      w2 = w2.reshape(hiddensizes[1],hiddensizes[0])\n",
        "      w3 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]]\n",
        "      w3 = w3.reshape(hiddensizes[2],hiddensizes[1])\n",
        "      w4 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2]: hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*784+hiddensizes[1]*hiddensizes[2] +hiddensizes[2]*10]\n",
        "      w4 = w4.reshape(10 , hiddensizes[2])\n",
        "\n",
        "      wf =torch.load('weights_f.pth')\n",
        "      wf['0.weight'] = torch.from_numpy(w1)\n",
        "      wf['2.weight'] = torch.from_numpy(w2)\n",
        "      wf['4.weight'] = torch.from_numpy(w3)\n",
        "      wf['6.weight'] = torch.from_numpy(w4)\n",
        "      torch.save(wf,'w_affex.pth')\n",
        "\n",
        "\n",
        "      net.load_state_dict(torch.load('w_affex.pth'))\n",
        "      #testing\n",
        "      correct_count, all_count = 0, 0\n",
        "      for images,labels in valloader:\n",
        "          for i in range(len(labels)):\n",
        "              img = images[i].view(1, 784)\n",
        "              with torch.no_grad():\n",
        "                  logps = net(img)\n",
        "\n",
        "\n",
        "              ps = torch.exp(logps)\n",
        "              probab = list(ps.numpy()[0])\n",
        "              pred_label = probab.index(max(probab))\n",
        "              true_label = labels.numpy()[i]\n",
        "              if(true_label == pred_label):\n",
        "                    correct_count += 1\n",
        "              all_count += 1\n",
        "\n",
        "      acc[i_out,i_in] = correct_count/all_count\n",
        "      dist_i[i_out,i_in] = np.linalg.norm(w-w_init)\n",
        "      dist_f[i_out,i_in] = np.linalg.norm(w-wf_vec)\n",
        "      print(\"\\n n_rows = {0} , Accuracy ={1}\".format(n_rows,acc[i_out,i_in]))\n",
        "      print(\"\\n Dist from Wi = {0} , Dist from Wf ={1}\".format(dist_i[i_out,i_in],dist_f[i_out,i_in]))    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outer iteration number: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " n_rows = 2 , Accuracy =0.1049\n",
            "\n",
            " Dist from Wi = 0.029207059017898943 , Dist from Wf =9.15667052208142\n",
            "\n",
            " n_rows = 4 , Accuracy =0.1075\n",
            "\n",
            " Dist from Wi = 0.15615469081202898 , Dist from Wf =9.155385508802386\n",
            "\n",
            " n_rows = 8 , Accuracy =0.1067\n",
            "\n",
            " Dist from Wi = 0.1659847597156032 , Dist from Wf =9.155212567810398\n",
            "\n",
            " n_rows = 16 , Accuracy =0.1114\n",
            "\n",
            " Dist from Wi = 0.33155353795494297 , Dist from Wf =9.150712559889579\n",
            "\n",
            " n_rows = 32 , Accuracy =0.1014\n",
            "\n",
            " Dist from Wi = 0.5068886889927814 , Dist from Wf =9.142676411162242\n",
            "\n",
            " n_rows = 64 , Accuracy =0.0997\n",
            "\n",
            " Dist from Wi = 0.7189085260401408 , Dist from Wf =9.128452148827758\n",
            "\n",
            " n_rows = 128 , Accuracy =0.0997\n",
            "\n",
            " Dist from Wi = 1.1126750108440238 , Dist from Wf =9.088862548333239\n",
            "\n",
            " n_rows = 256 , Accuracy =0.1046\n",
            "\n",
            " Dist from Wi = 1.5009246103144818 , Dist from Wf =9.032867397255627\n",
            "\n",
            " n_rows = 512 , Accuracy =0.1089\n",
            "\n",
            " Dist from Wi = 2.002033035897218 , Dist from Wf =8.935173855355446\n",
            "\n",
            " n_rows = 1024 , Accuracy =0.1047\n",
            "\n",
            " Dist from Wi = 2.8855426339242727 , Dist from Wf =8.690173289990064\n",
            "\n",
            " n_rows = 2048 , Accuracy =0.1026\n",
            "\n",
            " Dist from Wi = 3.22231033479223 , Dist from Wf =8.571008354245288\n",
            "\n",
            " n_rows = 4096 , Accuracy =0.1326\n",
            "\n",
            " Dist from Wi = 3.5019177189272486 , Dist from Wf =8.460617021950277\n",
            "\n",
            " n_rows = 8192 , Accuracy =0.1615\n",
            "\n",
            " Dist from Wi = 3.963941880831508 , Dist from Wf =8.25424938244789\n",
            "\n",
            " n_rows = 16384 , Accuracy =0.1786\n",
            "\n",
            " Dist from Wi = 4.695068084616148 , Dist from Wf =7.861412327506445\n",
            "\n",
            " n_rows = 32768 , Accuracy =0.2776\n",
            "\n",
            " Dist from Wi = 6.0347576618380945 , Dist from Wf =6.886738565180018\n",
            "\n",
            " n_rows = 65536 , Accuracy =0.6572\n",
            "\n",
            " Dist from Wi = 7.09805521667151 , Dist from Wf =5.784728190964005\n",
            "\n",
            " n_rows = 100352 , Accuracy =0.8843\n",
            "\n",
            " Dist from Wi = 8.070985327990684 , Dist from Wf =4.324888893094298\n",
            "\n",
            " n_rows = 116736 , Accuracy =0.9582\n",
            "\n",
            " Dist from Wi = 8.650843157562296 , Dist from Wf =3.0013964692304413\n",
            "\n",
            " n_rows = 131072 , Accuracy =0.9735\n",
            "\n",
            " Dist from Wi = 9.05524678216254 , Dist from Wf =1.3594020069082986\n",
            "\n",
            " n_rows = 133120 , Accuracy =0.975\n",
            "\n",
            " Dist from Wi = 9.112717450107793 , Dist from Wf =0.8965761410790734\n",
            "\n",
            " n_rows = 134400 , Accuracy =0.9758\n",
            "\n",
            " Dist from Wi = 9.156717102884162 , Dist from Wf =0.0\n",
            "\n",
            " n_rows = 262144 , Accuracy =0.9758\n",
            "\n",
            " Dist from Wi = 9.156717102884162 , Dist from Wf =0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrdHZU0SzuHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"accuracy_UI3.npy\", acc)\n",
        "np.save(\"distance_i_UI3.npy\", dist_i)\n",
        "np.save(\"distance_f_UI3.npy\", dist_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQFCc_JLvzRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I UI for cifar 192"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUYxcV5I1t6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "aef60031-1f9c-4dd9-8f25-1b728668ae3e"
      },
      "source": [
        "!pip install q scipy==1.1.0\n",
        "import numpy as np\n",
        "import torch \n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from time import time \n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn,optim \n",
        "import torch.nn.functional as F\n",
        "from scipy.sparse.linalg import lsqr\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse import random\n",
        "from scipy.sparse import rand\n",
        "from scipy import stats\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: q in /usr/local/lib/python3.6/dist-packages (2.6)\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LKkXVrx0X7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "14faa59f-c6f5-46b8-aec5-a692f16f8f78"
      },
      "source": [
        "cuda = torch.device('cuda')     # Default CUDA device\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNJIM_bxzq7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "\n",
        "#define the model \n",
        "inputsize = 3*32*32\n",
        "hiddensizes = [192,192,192]\n",
        "outputsize = 10\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0],-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzj8PVxLzvXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8dfba500-f0a8-417b-a7fb-9dea7b5e9a6f"
      },
      "source": [
        "#Rerun for randomizing w_init\n",
        "\n",
        "net = nn.Sequential(nn.Linear(inputsize,hiddensizes[0]),nn.ReLU(),nn.Linear(hiddensizes[0],hiddensizes[1]),nn.ReLU(),\n",
        "                    nn.Linear(hiddensizes[1],hiddensizes[2]),nn.ReLU(),nn.Linear(hiddensizes[2],outputsize),nn.LogSoftmax(dim=1))\n",
        "net.apply(init_weights)\n",
        "\n",
        "w_init= list(net.parameters())\n",
        "torch.save(net.state_dict(),'weights_i.pth')\n",
        "\n",
        "print(net)\n",
        "logps = (net(images))\n",
        "loss = criterion(logps,labels)\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(),lr = 0.003, momentum = 0.9 )\n",
        "time0 = time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=3072, out_features=192, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=192, out_features=192, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=192, out_features=192, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=192, out_features=10, bias=True)\n",
            "  (7): LogSoftmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-AlLGSAzydt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "outputId": "de9e5665-ce7a-424e-a710-c45322e1c527"
      },
      "source": [
        "epochs =15\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images,labels in trainloader:\n",
        "        images = images.view(images.shape[0],-1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = net(images)\n",
        "        loss = criterion(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss+=loss.item()\n",
        "#     else:\n",
        "    print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "#     print(running_loss)\n",
        "            \n",
        "    print(\"\\n Training time in minutes = \", (time()-time0)/60)\n",
        "    \n",
        "    torch.save(net.state_dict(),'weights_f.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - Training loss: 1.7301762326599082\n",
            "\n",
            " Training time in minutes =  0.1356374979019165\n",
            "Epoch 1 - Training loss: 1.4857225832731829\n",
            "\n",
            " Training time in minutes =  0.2702988942464193\n",
            "Epoch 2 - Training loss: 1.3768593379298744\n",
            "\n",
            " Training time in minutes =  0.40099146366119387\n",
            "Epoch 3 - Training loss: 1.2944727700842007\n",
            "\n",
            " Training time in minutes =  0.5364514191945394\n",
            "Epoch 4 - Training loss: 1.2252646199882489\n",
            "\n",
            " Training time in minutes =  0.6687025944391887\n",
            "Epoch 5 - Training loss: 1.1694155118197127\n",
            "\n",
            " Training time in minutes =  0.8046006441116333\n",
            "Epoch 6 - Training loss: 1.1147881231801895\n",
            "\n",
            " Training time in minutes =  0.9402898788452149\n",
            "Epoch 7 - Training loss: 1.0640769529982905\n",
            "\n",
            " Training time in minutes =  1.0735091368357341\n",
            "Epoch 8 - Training loss: 1.0209258730759097\n",
            "\n",
            " Training time in minutes =  1.2061952193578085\n",
            "Epoch 9 - Training loss: 0.972156114056897\n",
            "\n",
            " Training time in minutes =  1.3357619444529216\n",
            "Epoch 10 - Training loss: 0.9252163156524034\n",
            "\n",
            " Training time in minutes =  1.4694260279337565\n",
            "Epoch 11 - Training loss: 0.883568821660698\n",
            "\n",
            " Training time in minutes =  1.6027141729990642\n",
            "Epoch 12 - Training loss: 0.8438807470947886\n",
            "\n",
            " Training time in minutes =  1.7354023019472757\n",
            "Epoch 13 - Training loss: 0.7981464090707052\n",
            "\n",
            " Training time in minutes =  1.8684462189674378\n",
            "Epoch 14 - Training loss: 0.7664280268542297\n",
            "\n",
            " Training time in minutes =  1.9986528833707173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQXxALWtz1W_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "0e2e404e-a0a2-41d0-f057-3c005fd76750"
      },
      "source": [
        "#testing\n",
        "correct_count, all_count = 0, 0\n",
        "for images,labels in testloader:\n",
        "    for i in range(len(labels)):\n",
        "        img = images[i].view(1, 3072)\n",
        "        with torch.no_grad():\n",
        "            logps = net(img)\n",
        "\n",
        "\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.numpy()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.numpy()[i]\n",
        "        if(true_label == pred_label):\n",
        "              correct_count += 1\n",
        "        all_count += 1\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))\n",
        "np.save('model_accuracy_5.npy',(correct_count/all_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Images Tested = 10000\n",
            "\n",
            "Model Accuracy = 0.5337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03vmD-Rtz5YQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f5e63baf-dff3-42a7-bcd0-9e244188dfeb"
      },
      "source": [
        "#Projecting weights on affine spaces defined by the set P: {AW = AW_final} \n",
        "#Projection is done using L2 minimization w= argmin ||w-w_initial|| in P\n",
        "\n",
        "#vectorize W\n",
        "wf =torch.load('weights_f.pth')\n",
        "wf1 = np.asarray(wf['0.weight'].resize(1,hiddensizes[0]*inputsize))\n",
        "wf2 = np.asarray(wf['2.weight'].resize(1,hiddensizes[0]*hiddensizes[1]))\n",
        "wf3 = np.asarray(wf['4.weight'].resize(1,hiddensizes[1]*hiddensizes[2]))\n",
        "wf4 = np.asarray(wf['6.weight'].resize(1,hiddensizes[2]*10))\n",
        "wf_vec = np.concatenate((wf1,wf2,wf3,wf4),axis =1)\n",
        "wf_vec = wf_vec.T\n",
        "dim_w = wf_vec.shape[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK756EDqBelW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e148207d-2889-4a4e-e3a6-10ea16f6f13d"
      },
      "source": [
        "dim_w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "665472"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y570sdbXB_aF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bfc6f390-0b86-49c2-8277-12297589ed28"
      },
      "source": [
        "131072*4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "524288"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ukIu3aM0ATr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "588f41b0-7156-46c9-e181-74a7982d78ee"
      },
      "source": [
        "#w_init ,I run  1\n",
        "from scipy import sparse\n",
        "n_runs =1\n",
        "num_rows_arr  = np.asarray([2,4,8,16,32,64,128,256,512,1024,2048,4096,8192, 16384,32768,65536,131072,262144,524288,192*3074,192*192 + 192*3074, 192*192 + 192*192 + 192*3074, 1920+192*192 + 192*192 + 192*3074])\n",
        "num_rows_arr = np.sort(num_rows_arr)\n",
        "\n",
        "den = 10/dim_w\n",
        "I = sparse.identity(dim_w)\n",
        "acc  = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_i = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_f = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "rvs = stats.norm().rvs\n",
        "\n",
        "wi = torch.load('weights_i.pth')\n",
        "wi1 = np.asarray(wi['0.weight'].resize(1,hiddensizes[0]*inputsize))\n",
        "wi2 = np.asarray(wi['2.weight'].resize(1,hiddensizes[0]*hiddensizes[1]))\n",
        "wi3 = np.asarray(wi['4.weight'].resize(1,hiddensizes[1]*hiddensizes[2]))\n",
        "wi4 = np.asarray(wi['6.weight'].resize(1,hiddensizes[2]*10))\n",
        "w_init = np.concatenate((wi1,wi2,wi3,wi4), axis = 1)\n",
        "w_init = w_init.T\n",
        "\n",
        "w_init.ravel()\n",
        "w_init.squeeze()\n",
        "\n",
        "for i_out in range(n_runs):\n",
        "  print(\"outer iteration number:\",(i_out+1))\n",
        "  for i_in in range(num_rows_arr.shape[0]):\n",
        "      \n",
        "      n_rows = num_rows_arr[i_in]\n",
        "      #minimize Z such that AZ = A(Wf-w_init)\n",
        "      w = np.zeros((dim_w,1))\n",
        "      w[0:n_rows] = wf_vec[0:n_rows]\n",
        "      w[n_rows:] = w_init[n_rows:] \n",
        "\n",
        "      #test performance of this reinitialization\n",
        "      w1= w[0:hiddensizes[0]*inputsize]\n",
        "      w1 = w1.reshape(hiddensizes[0] , inputsize)\n",
        "      w2 = w[hiddensizes[0]*inputsize:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*inputsize]\n",
        "      w2 = w2.reshape(hiddensizes[1],hiddensizes[0])\n",
        "      w3 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*inputsize:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*inputsize+hiddensizes[1]*hiddensizes[2]]\n",
        "      w3 = w3.reshape(hiddensizes[2],hiddensizes[1])\n",
        "      w4 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*inputsize+hiddensizes[1]*hiddensizes[2]: hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*inputsize+hiddensizes[1]*hiddensizes[2] +hiddensizes[2]*10]\n",
        "      w4 = w4.reshape(10 , hiddensizes[2])\n",
        "\n",
        "      wf =torch.load('weights_f.pth')\n",
        "      wf['0.weight'] = torch.from_numpy(w1)\n",
        "      wf['2.weight'] = torch.from_numpy(w2)\n",
        "      wf['4.weight'] = torch.from_numpy(w3)\n",
        "      wf['6.weight'] = torch.from_numpy(w4)\n",
        "      torch.save(wf,'w_affex.pth')\n",
        "\n",
        "      net.load_state_dict(torch.load('w_affex.pth'))\n",
        "\n",
        "      #testing\n",
        "      correct_count, all_count = 0, 0\n",
        "      for images,labels in testloader:\n",
        "          for i in range(len(labels)):\n",
        "              img = images[i].view(1, inputsize)\n",
        "              with torch.no_grad():\n",
        "                  logps = net(img)\n",
        "\n",
        "              ps = torch.exp(logps)\n",
        "              probab = list(ps.numpy()[0])\n",
        "              pred_label = probab.index(max(probab))\n",
        "              true_label = labels.numpy()[i]\n",
        "              if(true_label == pred_label):\n",
        "                    correct_count += 1\n",
        "              all_count += 1\n",
        "\n",
        "      acc[i_out,i_in] = correct_count/all_count\n",
        "      dist_i[i_out,i_in] = np.linalg.norm(w-w_init)\n",
        "      dist_f[i_out,i_in] = np.linalg.norm(w-wf_vec)\n",
        "      print(\"\\n n_rows = {0} , Accuracy ={1}\".format(n_rows,acc[i_out,i_in]))\n",
        "      print(\"\\n Dist from Wi = {0} , Dist from Wf ={1}\".format(dist_i[i_out,i_in],dist_f[i_out,i_in]))    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outer iteration number: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " n_rows = 2 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.014752055747059985 , Dist from Wf =14.98614027865965\n",
            "\n",
            " n_rows = 4 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.015511568699616817 , Dist from Wf =14.986139511763875\n",
            "\n",
            " n_rows = 8 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.030715711109030642 , Dist from Wf =14.986116061872236\n",
            "\n",
            " n_rows = 16 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.036546823044637314 , Dist from Wf =14.98610297590869\n",
            "\n",
            " n_rows = 32 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.05627827616530191 , Dist from Wf =14.986041866698685\n",
            "\n",
            " n_rows = 64 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.0770530421684065 , Dist from Wf =14.985949449517923\n",
            "\n",
            " n_rows = 128 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.113944783570084 , Dist from Wf =14.985714352713089\n",
            "\n",
            " n_rows = 256 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.1844307031199973 , Dist from Wf =14.985012625639012\n",
            "\n",
            " n_rows = 512 , Accuracy =0.1117\n",
            "\n",
            " Dist from Wi = 0.3931761496516771 , Dist from Wf =14.980988972366243\n",
            "\n",
            " n_rows = 1024 , Accuracy =0.1116\n",
            "\n",
            " Dist from Wi = 0.488306390051488 , Dist from Wf =14.978189975569437\n",
            "\n",
            " n_rows = 2048 , Accuracy =0.1115\n",
            "\n",
            " Dist from Wi = 0.7052839277727514 , Dist from Wf =14.969542165879334\n",
            "\n",
            " n_rows = 4096 , Accuracy =0.1136\n",
            "\n",
            " Dist from Wi = 1.0465198972376968 , Dist from Wf =14.949562340734243\n",
            "\n",
            " n_rows = 8192 , Accuracy =0.1163\n",
            "\n",
            " Dist from Wi = 1.4840575475038558 , Dist from Wf =14.912484409732361\n",
            "\n",
            " n_rows = 16384 , Accuracy =0.1144\n",
            "\n",
            " Dist from Wi = 2.112022903102873 , Dist from Wf =14.836575660562065\n",
            "\n",
            " n_rows = 32768 , Accuracy =0.127\n",
            "\n",
            " Dist from Wi = 3.0301588167007143 , Dist from Wf =14.676605725452482\n",
            "\n",
            " n_rows = 65536 , Accuracy =0.122\n",
            "\n",
            " Dist from Wi = 4.215139001410703 , Dist from Wf =14.381141167292665\n",
            "\n",
            " n_rows = 131072 , Accuracy =0.1293\n",
            "\n",
            " Dist from Wi = 5.847960104475528 , Dist from Wf =13.798042639855707\n",
            "\n",
            " n_rows = 262144 , Accuracy =0.1413\n",
            "\n",
            " Dist from Wi = 8.244632034529294 , Dist from Wf =12.514418112322558\n",
            "\n",
            " n_rows = 524288 , Accuracy =0.2016\n",
            "\n",
            " Dist from Wi = 11.608930115665835 , Dist from Wf =9.477202100008224\n",
            "\n",
            " n_rows = 590208 , Accuracy =0.2321\n",
            "\n",
            " Dist from Wi = 12.355486133954368 , Dist from Wf =8.480953983395652\n",
            "\n",
            " n_rows = 627072 , Accuracy =0.3489\n",
            "\n",
            " Dist from Wi = 13.75437049005522 , Dist from Wf =5.949950461735926\n",
            "\n",
            " n_rows = 663936 , Accuracy =0.4643\n",
            "\n",
            " Dist from Wi = 14.646147469903662 , Dist from Wf =3.174111271623692\n",
            "\n",
            " n_rows = 665856 , Accuracy =0.5337\n",
            "\n",
            " Dist from Wi = 14.986147539471709 , Dist from Wf =0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pmXZ-DN06_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"accuracy_I3.npy\", acc)\n",
        "np.save(\"distance_i_I3.npy\", dist_i)\n",
        "np.save(\"distance_f_I3.npy\", dist_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1n84S7l1QQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e40bb630-3967-49d6-acc1-e5aee3ee42d1"
      },
      "source": [
        "#w_init ,Irev run  1\n",
        "from scipy import sparse\n",
        "n_runs =1\n",
        "num_rows_arr  = np.asarray([2,4,8,16,32,64,128,256,512,1024,2048,4096,8192, 16384,32768,65536,131072,262144,524288,192*3074,192*192 + 192*3074, 192*192 + 192*192 + 192*3074, 1920+192*192 + 192*192 + 192*3074])\n",
        "num_rows_arr = np.sort(num_rows_arr)\n",
        "\n",
        "den = 10/dim_w\n",
        "I = sparse.identity(dim_w)\n",
        "acc  = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_i = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "dist_f = np.zeros((n_runs,num_rows_arr.shape[0]))\n",
        "rvs = stats.norm().rvs\n",
        "\n",
        "wi = torch.load('weights_i.pth')\n",
        "wi1 = np.asarray(wi['0.weight'].resize(1,hiddensizes[0]*inputsize))\n",
        "wi2 = np.asarray(wi['2.weight'].resize(1,hiddensizes[0]*hiddensizes[1]))\n",
        "wi3 = np.asarray(wi['4.weight'].resize(1,hiddensizes[1]*hiddensizes[2]))\n",
        "wi4 = np.asarray(wi['6.weight'].resize(1,hiddensizes[2]*10))\n",
        "w_init = np.concatenate((wi1,wi2,wi3,wi4), axis = 1)\n",
        "w_init = w_init.T\n",
        "\n",
        "w_init.ravel()\n",
        "w_init.squeeze()\n",
        "\n",
        "for i_out in range(n_runs):\n",
        "  print(\"outer iteration number:\",(i_out+1))\n",
        "  for i_in in range(num_rows_arr.shape[0]):\n",
        "      \n",
        "      n_rows = num_rows_arr[i_in]\n",
        "      #minimize Z such that AZ = A(Wf-w_init)\n",
        "      w = np.zeros((dim_w,1))\n",
        "      w[0:-n_rows] = w_init[0:-n_rows]\n",
        "      w[-n_rows:] = wf_vec[-n_rows:] \n",
        "\n",
        "      #test performance of this reinitialization\n",
        "      w1= w[0:hiddensizes[0]*inputsize]\n",
        "      w1 = w1.reshape(hiddensizes[0] , inputsize)\n",
        "      w2 = w[hiddensizes[0]*inputsize:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*inputsize]\n",
        "      w2 = w2.reshape(hiddensizes[1],hiddensizes[0])\n",
        "      w3 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*inputsize:hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*inputsize+hiddensizes[1]*hiddensizes[2]]\n",
        "      w3 = w3.reshape(hiddensizes[2],hiddensizes[1])\n",
        "      w4 = w[hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*inputsize+hiddensizes[1]*hiddensizes[2]: hiddensizes[1]*hiddensizes[0]+hiddensizes[0]*inputsize+hiddensizes[1]*hiddensizes[2] +hiddensizes[2]*10]\n",
        "      w4 = w4.reshape(10 , hiddensizes[2])\n",
        "\n",
        "      wf =torch.load('weights_f.pth')\n",
        "      wf['0.weight'] = torch.from_numpy(w1)\n",
        "      wf['2.weight'] = torch.from_numpy(w2)\n",
        "      wf['4.weight'] = torch.from_numpy(w3)\n",
        "      wf['6.weight'] = torch.from_numpy(w4)\n",
        "      torch.save(wf,'w_affex.pth')\n",
        "\n",
        "      net.load_state_dict(torch.load('w_affex.pth'))\n",
        "\n",
        "      #testing\n",
        "      correct_count, all_count = 0, 0\n",
        "      for images,labels in testloader:\n",
        "          for i in range(len(labels)):\n",
        "              img = images[i].view(1, inputsize)\n",
        "              with torch.no_grad():\n",
        "                  logps = net(img)\n",
        "\n",
        "              ps = torch.exp(logps)\n",
        "              probab = list(ps.numpy()[0])\n",
        "              pred_label = probab.index(max(probab))\n",
        "              true_label = labels.numpy()[i]\n",
        "              if(true_label == pred_label):\n",
        "                    correct_count += 1\n",
        "              all_count += 1\n",
        "\n",
        "      acc[i_out,i_in] = correct_count/all_count\n",
        "      dist_i[i_out,i_in] = np.linalg.norm(w-w_init)\n",
        "      dist_f[i_out,i_in] = np.linalg.norm(w-wf_vec)\n",
        "      print(\"\\n n_rows = {0} , Accuracy ={1}\".format(n_rows,acc[i_out,i_in]))\n",
        "      print(\"\\n Dist from Wi = {0} , Dist from Wf ={1}\".format(dist_i[i_out,i_in],dist_f[i_out,i_in]))    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outer iteration number: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:365: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " n_rows = 2 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.15277687604415321 , Dist from Wf =14.985368774273129\n",
            "\n",
            " n_rows = 4 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.21155790818553227 , Dist from Wf =14.984654194418304\n",
            "\n",
            " n_rows = 8 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.253756875906661 , Dist from Wf =14.98399898300664\n",
            "\n",
            " n_rows = 16 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.37760930717716795 , Dist from Wf =14.981389431089065\n",
            "\n",
            " n_rows = 32 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.5656301133623804 , Dist from Wf =14.975469296475206\n",
            "\n",
            " n_rows = 64 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.6747281956809028 , Dist from Wf =14.97095053551267\n",
            "\n",
            " n_rows = 128 , Accuracy =0.111\n",
            "\n",
            " Dist from Wi = 0.9341397526912444 , Dist from Wf =14.95700508114027\n",
            "\n",
            " n_rows = 256 , Accuracy =0.1113\n",
            "\n",
            " Dist from Wi = 1.3104465901213587 , Dist from Wf =14.928742338497683\n",
            "\n",
            " n_rows = 512 , Accuracy =0.1117\n",
            "\n",
            " Dist from Wi = 1.9178118809078402 , Dist from Wf =14.862927560351718\n",
            "\n",
            " n_rows = 1024 , Accuracy =0.1055\n",
            "\n",
            " Dist from Wi = 2.6612565749496966 , Dist from Wf =14.747960249373504\n",
            "\n",
            " n_rows = 2048 , Accuracy =0.1196\n",
            "\n",
            " Dist from Wi = 3.624576763368561 , Dist from Wf =14.541219390452188\n",
            "\n",
            " n_rows = 4096 , Accuracy =0.1192\n",
            "\n",
            " Dist from Wi = 3.7833284866414387 , Dist from Wf =14.500725624498292\n",
            "\n",
            " n_rows = 8192 , Accuracy =0.1298\n",
            "\n",
            " Dist from Wi = 4.122608776432319 , Dist from Wf =14.407939302735043\n",
            "\n",
            " n_rows = 16384 , Accuracy =0.1341\n",
            "\n",
            " Dist from Wi = 4.636951593964497 , Dist from Wf =14.250729735351939\n",
            "\n",
            " n_rows = 32768 , Accuracy =0.1406\n",
            "\n",
            " Dist from Wi = 5.612672183218407 , Dist from Wf =13.895413957077341\n",
            "\n",
            " n_rows = 65536 , Accuracy =0.171\n",
            "\n",
            " Dist from Wi = 7.900226561742968 , Dist from Wf =12.734639309691667\n",
            "\n",
            " n_rows = 131072 , Accuracy =0.2323\n",
            "\n",
            " Dist from Wi = 9.306608842367535 , Dist from Wf =11.74613340337916\n",
            "\n",
            " n_rows = 262144 , Accuracy =0.3285\n",
            "\n",
            " Dist from Wi = 10.99213612012993 , Dist from Wf =10.186145570889336\n",
            "\n",
            " n_rows = 524288 , Accuracy =0.481\n",
            "\n",
            " Dist from Wi = 13.71206333704841 , Dist from Wf =6.046812144889785\n",
            "\n",
            " n_rows = 590208 , Accuracy =0.5129\n",
            "\n",
            " Dist from Wi = 14.297066472608156 , Dist from Wf =4.492049460172635\n",
            "\n",
            " n_rows = 627072 , Accuracy =0.5205\n",
            "\n",
            " Dist from Wi = 14.62628981879666 , Dist from Wf =3.26439339102669\n",
            "\n",
            " n_rows = 663936 , Accuracy =0.5364\n",
            "\n",
            " Dist from Wi = 14.972701970368064 , Dist from Wf =0.6346761231921656\n",
            "\n",
            " n_rows = 665856 , Accuracy =0.5337\n",
            "\n",
            " Dist from Wi = 14.986147539471709 , Dist from Wf =0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU62ne_n3aGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"accuracy_UI3.npy\", acc)\n",
        "np.save(\"distance_i_UI3.npy\", dist_i)\n",
        "np.save(\"distance_f_UI3.npy\", dist_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fucOXvDJ36W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}